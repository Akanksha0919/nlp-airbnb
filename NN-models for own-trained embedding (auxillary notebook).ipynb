{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Advanced Data Analytics for Management Support - Assignment Submission","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n        1. Introduction\n        2. Model Selection\n            2.1 Data preparation\n            2.2 RNN Architecture (unstructured data)\n            2.2.1 LSTM\n            2.2.2 Bidirectional LSTM\n            2.2.3 CNN-LSTM\n        3. Full Model Architecture\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"In this auxillary code file we have trained NLP models using self-trained word embeddings.The results from this notebook are referred in the main notebook \"w2v pretrained modeling airbnb.ipnyb\". \n\nThe task of this assignment is to predict the price of propertied hosted on an online marketplace for accommodation rental called as Airbnb, based on different webscraped features like the location, number of rooms, property type, texts with the listing description, and rental price per night.The main focus hereby lies on building an NN-based model that predicts the price of listings in the unseen dataset based on both text and tabular data.\n","metadata":{}},{"cell_type":"code","source":"!pip install textstat","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:11:49.175430Z","iopub.execute_input":"2022-09-09T21:11:49.175881Z","iopub.status.idle":"2022-09-09T21:12:01.047748Z","shell.execute_reply.started":"2022-09-09T21:11:49.175801Z","shell.execute_reply":"2022-09-09T21:12:01.046523Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting textstat\n  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting pyphen\n  Downloading pyphen-0.13.0-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, textstat\nSuccessfully installed pyphen-0.13.0 textstat-0.7.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\nimport datetime\nimport time\nimport textstat\nfrom bs4 import BeautifulSoup\nfrom collections import Counter\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom gensim.models import KeyedVectors\nfrom gensim.models.keyedvectors import Word2VecKeyedVectors\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, concatenate, Dense, Embedding, LSTM, GRU, Bidirectional, BatchNormalization, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.initializers import Constant\nfrom tensorflow.keras import activations, losses\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras import layers, models, optimizers, losses\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nimport numpy as np # linear algebra\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport nltk  \n\nfrom tensorflow.keras import layers, models, optimizers, losses\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom numpy import mean\nfrom numpy import absolute\nfrom numpy import sqrt\n\n\nimport tensorflow as tf\nimport string\nimport statistics\nimport math\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n\nnltk.download('omw-1.4')\n# When running this notebook for the first time, you have to download some NLTK packages. To do so, simply uncomment the next lines\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:01.050361Z","iopub.execute_input":"2022-09-09T21:12:01.050817Z","iopub.status.idle":"2022-09-09T21:12:08.931843Z","shell.execute_reply.started":"2022-09-09T21:12:01.050771Z","shell.execute_reply":"2022-09-09T21:12:08.930100Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!pip install gensim==4.2.0 ","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:08.933497Z","iopub.execute_input":"2022-09-09T21:12:08.934476Z","iopub.status.idle":"2022-09-09T21:12:21.552340Z","shell.execute_reply.started":"2022-09-09T21:12:08.934436Z","shell.execute_reply":"2022-09-09T21:12:21.551185Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gensim==4.2.0\n  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.21.6)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (1.7.3)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.2.0) (5.2.1)\nInstalling collected packages: gensim\n  Attempting uninstall: gensim\n    Found existing installation: gensim 4.0.1\n    Uninstalling gensim-4.0.1:\n      Successfully uninstalled gensim-4.0.1\nSuccessfully installed gensim-4.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_pickle('../input/airbnb-last-version-numerical-data/x_train.pkl')\ntest = pd.read_pickle('../input/airbnb-last-version-numerical-data/x_test.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:21.556808Z","iopub.execute_input":"2022-09-09T21:12:21.557142Z","iopub.status.idle":"2022-09-09T21:12:23.765844Z","shell.execute_reply.started":"2022-09-09T21:12:21.557111Z","shell.execute_reply":"2022-09-09T21:12:23.764858Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:23.767454Z","iopub.execute_input":"2022-09-09T21:12:23.767820Z","iopub.status.idle":"2022-09-09T21:12:23.866856Z","shell.execute_reply.started":"2022-09-09T21:12:23.767782Z","shell.execute_reply":"2022-09-09T21:12:23.865764Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 55284 entries, 0 to 55283\nData columns (total 48 columns):\n #   Column                                 Non-Null Count  Dtype         \n---  ------                                 --------------  -----         \n 0   host_is_superhost                      55284 non-null  float64       \n 1   reviews_per_month                      55284 non-null  float64       \n 2   room_type_Private room                 55284 non-null  uint8         \n 3   bed_type_Real Bed                      55284 non-null  uint8         \n 4   bed_type_Pull-out Sofa                 55284 non-null  uint8         \n 5   bedrooms                               55284 non-null  float64       \n 6   bed_type_Couch                         55284 non-null  uint8         \n 7   beds                                   55284 non-null  float64       \n 8   room_type_Shared room                  55284 non-null  uint8         \n 9   review_scores_location                 55284 non-null  float64       \n 10  guests_included                        55284 non-null  float64       \n 11  bed_type_Futon                         55284 non-null  uint8         \n 12  review_scores_rating                   55284 non-null  float64       \n 13  house_rules                            31906 non-null  object        \n 14  summary                                52330 non-null  object        \n 15  host_identity_verified                 55284 non-null  float64       \n 16  host_has_profile_pic                   55284 non-null  float64       \n 17  review_scores_accuracy                 55284 non-null  float64       \n 18  host_response_time_within a day        55284 non-null  uint8         \n 19  space                                  38403 non-null  object        \n 20  review_scores_cleanliness              55284 non-null  float64       \n 21  picture_url                            55284 non-null  object        \n 22  listing_id                             55284 non-null  object        \n 23  host_since                             55284 non-null  datetime64[ns]\n 24  host_response_rate                     37482 non-null  object        \n 25  neighbourhood                          55137 non-null  object        \n 26  host_response_time_within an hour      55284 non-null  uint8         \n 27  name                                   55270 non-null  object        \n 28  review_scores_value                    55284 non-null  float64       \n 29  host_total_listings_count              55284 non-null  float64       \n 30  amenities                              55284 non-null  object        \n 31  experiences_offered                    55284 non-null  object        \n 32  review_scores_checkin                  55284 non-null  float64       \n 33  host_days                              55284 non-null  float64       \n 34  host_response_time_missing             55284 non-null  uint8         \n 35  host_response_rate_num                 55284 non-null  float64       \n 36  review_scores_communication            55284 non-null  float64       \n 37  transit                                35477 non-null  object        \n 38  accommodates                           55284 non-null  float64       \n 39  host_response_time_within a few hours  55284 non-null  uint8         \n 40  neighborhood_overview                  35778 non-null  object        \n 41  room_type_Hotel room                   55284 non-null  uint8         \n 42  bathrooms                              55284 non-null  float64       \n 43  description                            53558 non-null  object        \n 44  cancellation_policy_woe                55284 non-null  float64       \n 45  property_type_woe                      55284 non-null  float64       \n 46  neighbourhood_cleansed_woe             55284 non-null  float64       \n 47  price                                  55284 non-null  float64       \ndtypes: datetime64[ns](1), float64(23), object(13), uint8(11)\nmemory usage: 16.2+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.isnull().sum()/55284 * 100\n","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:23.868512Z","iopub.execute_input":"2022-09-09T21:12:23.868881Z","iopub.status.idle":"2022-09-09T21:12:23.940418Z","shell.execute_reply.started":"2022-09-09T21:12:23.868845Z","shell.execute_reply":"2022-09-09T21:12:23.939286Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"host_is_superhost                         0.000000\nreviews_per_month                         0.000000\nroom_type_Private room                    0.000000\nbed_type_Real Bed                         0.000000\nbed_type_Pull-out Sofa                    0.000000\nbedrooms                                  0.000000\nbed_type_Couch                            0.000000\nbeds                                      0.000000\nroom_type_Shared room                     0.000000\nreview_scores_location                    0.000000\nguests_included                           0.000000\nbed_type_Futon                            0.000000\nreview_scores_rating                      0.000000\nhouse_rules                              42.287099\nsummary                                   5.343318\nhost_identity_verified                    0.000000\nhost_has_profile_pic                      0.000000\nreview_scores_accuracy                    0.000000\nhost_response_time_within a day           0.000000\nspace                                    30.535055\nreview_scores_cleanliness                 0.000000\npicture_url                               0.000000\nlisting_id                                0.000000\nhost_since                                0.000000\nhost_response_rate                       32.200998\nneighbourhood                             0.265900\nhost_response_time_within an hour         0.000000\nname                                      0.025324\nreview_scores_value                       0.000000\nhost_total_listings_count                 0.000000\namenities                                 0.000000\nexperiences_offered                       0.000000\nreview_scores_checkin                     0.000000\nhost_days                                 0.000000\nhost_response_time_missing                0.000000\nhost_response_rate_num                    0.000000\nreview_scores_communication               0.000000\ntransit                                  35.827726\naccommodates                              0.000000\nhost_response_time_within a few hours     0.000000\nneighborhood_overview                    35.283265\nroom_type_Hotel room                      0.000000\nbathrooms                                 0.000000\ndescription                               3.122061\ncancellation_policy_woe                   0.000000\nproperty_type_woe                         0.000000\nneighbourhood_cleansed_woe                0.000000\nprice                                     0.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Model Selection","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Data Preparation ","metadata":{}},{"cell_type":"markdown","source":"This notebook covers the embedding layer experimentation using Textvectorization form keras. We start with handling the null values in the text columns by replacing them with empty strings.\n\nLooking at the \"description\" feature we can see that it is a combination of summary,space and neighborhood_overview text features. In order to avoid redundant information in the pipeline, we chose to drop the description feature from the analysis. Also, since \"description\" feature is relatively long as compared to summary,space and neighborhood_overview features, the context might get lost in dense layers of the NLP models. ","metadata":{}},{"cell_type":"code","source":"train['neighborhood_overview'].fillna('',inplace=True)\ntrain['space'].fillna('',inplace=True)\ntrain['summary'].fillna('',inplace=True)\ntrain['name'].fillna('',inplace=True)\ntrain['transit'].fillna('',inplace=True)\ntrain['house_rules'].fillna('',inplace=True)\ntrain['host_response_rate'].fillna(0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:23.942214Z","iopub.execute_input":"2022-09-09T21:12:23.942643Z","iopub.status.idle":"2022-09-09T21:12:23.989833Z","shell.execute_reply.started":"2022-09-09T21:12:23.942592Z","shell.execute_reply":"2022-09-09T21:12:23.988880Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test['neighborhood_overview'].fillna('',inplace=True)\ntest['space'].fillna('',inplace=True)\ntest['summary'].fillna('',inplace=True)\ntest['name'].fillna('',inplace=True)\ntest['transit'].fillna('',inplace=True)\ntest['house_rules'].fillna('',inplace=True)\ntest['host_response_rate'].fillna(0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:23.991276Z","iopub.execute_input":"2022-09-09T21:12:23.991605Z","iopub.status.idle":"2022-09-09T21:12:24.035853Z","shell.execute_reply.started":"2022-09-09T21:12:23.991571Z","shell.execute_reply":"2022-09-09T21:12:24.034645Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"text_cols = ['name', 'summary', 'space', 'neighborhood_overview', 'transit', 'house_rules','ameneties']","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:24.037417Z","iopub.execute_input":"2022-09-09T21:12:24.038002Z","iopub.status.idle":"2022-09-09T21:12:24.043947Z","shell.execute_reply.started":"2022-09-09T21:12:24.037966Z","shell.execute_reply":"2022-09-09T21:12:24.042620Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_name = train['name']\ntrain_summary = train['summary']\ntrain_space = train['space']\ntrain_ngbr = train['neighborhood_overview']\ntrain_transit = train['transit']\ntrain_hr = train['house_rules']\ny_train = train['price']\nprint(len(train_name), len(train_summary), len(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:24.049261Z","iopub.execute_input":"2022-09-09T21:12:24.050375Z","iopub.status.idle":"2022-09-09T21:12:24.065578Z","shell.execute_reply.started":"2022-09-09T21:12:24.050338Z","shell.execute_reply":"2022-09-09T21:12:24.063348Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"55284 55284 55284\n","output_type":"stream"}]},{"cell_type":"code","source":"test_name = test['name']\ntest_summary = test['summary']\ntest_space = test['space']\ntest_ngbr = test['neighborhood_overview']\ntest_transit = test['transit']\ntest_hr = test['house_rules']\nprint(len(test_name), len(test_summary))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:24.066937Z","iopub.execute_input":"2022-09-09T21:12:24.069427Z","iopub.status.idle":"2022-09-09T21:12:24.091729Z","shell.execute_reply.started":"2022-09-09T21:12:24.069390Z","shell.execute_reply":"2022-09-09T21:12:24.090131Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"29769 29769\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The number of hidden units in the NLP models is chosen to be 128. The embedding size is also fixed to 100 and the output sequence length is set to 500. ","metadata":{}},{"cell_type":"code","source":"vocab_size = 10000\nseq_length = 500\nemb_size = 100\nrnn_units = 128\ndef our_standardization(text_data):\n  lowercase = tf.strings.lower(text_data) # convert to lowercase\n  remove_html = tf.strings.regex_replace(lowercase, '<br />', ' ') # remove HTML tags\n  pattern_remove_punctuation = '[%s]' % re.escape(string.punctuation) # pattern to remove punctuation\n  remove_punct = tf.strings.regex_replace(remove_html, pattern_remove_punctuation, '') # apply pattern\n  remove_double_spaces = tf.strings.regex_replace(remove_punct, '\\s+', ' ') # remove double space\n  return remove_double_spaces\n\n# Create a vectorization layer\nvectorize_layer = TextVectorization(\n    standardize = our_standardization,\n    max_tokens = vocab_size,\n    output_sequence_length = seq_length\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:24.094275Z","iopub.execute_input":"2022-09-09T21:12:24.097136Z","iopub.status.idle":"2022-09-09T21:12:27.068242Z","shell.execute_reply.started":"2022-09-09T21:12:24.097086Z","shell.execute_reply":"2022-09-09T21:12:27.067271Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2022-09-09 21:12:24.228920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:24.364358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:24.365620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:24.368361: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-09 21:12:24.368788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:24.369828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:24.370747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:26.692694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:26.693551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:26.694246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-09 21:12:26.694845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2.2 RNN Architecture (unstructured data)","metadata":{}},{"cell_type":"code","source":"# Extract target variable and feature matrix \nX = train.drop(['price'], axis=1) \ny = train[['price']]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=888)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:27.070001Z","iopub.execute_input":"2022-09-09T21:12:27.070384Z","iopub.status.idle":"2022-09-09T21:12:27.179723Z","shell.execute_reply.started":"2022-09-09T21:12:27.070346Z","shell.execute_reply":"2022-09-09T21:12:27.178753Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"x_train_num_cols = X_train.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\nx_val_num_cols = X_val.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\nx_train_num_cols.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:27.181446Z","iopub.execute_input":"2022-09-09T21:12:27.181873Z","iopub.status.idle":"2022-09-09T21:12:27.210161Z","shell.execute_reply.started":"2022-09-09T21:12:27.181830Z","shell.execute_reply":"2022-09-09T21:12:27.209262Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 44227 entries, 25103 to 10750\nData columns (total 33 columns):\n #   Column                                 Non-Null Count  Dtype  \n---  ------                                 --------------  -----  \n 0   host_is_superhost                      44227 non-null  float64\n 1   reviews_per_month                      44227 non-null  float64\n 2   room_type_Private room                 44227 non-null  uint8  \n 3   bed_type_Real Bed                      44227 non-null  uint8  \n 4   bed_type_Pull-out Sofa                 44227 non-null  uint8  \n 5   bedrooms                               44227 non-null  float64\n 6   bed_type_Couch                         44227 non-null  uint8  \n 7   beds                                   44227 non-null  float64\n 8   room_type_Shared room                  44227 non-null  uint8  \n 9   review_scores_location                 44227 non-null  float64\n 10  guests_included                        44227 non-null  float64\n 11  bed_type_Futon                         44227 non-null  uint8  \n 12  review_scores_rating                   44227 non-null  float64\n 13  host_identity_verified                 44227 non-null  float64\n 14  host_has_profile_pic                   44227 non-null  float64\n 15  review_scores_accuracy                 44227 non-null  float64\n 16  host_response_time_within a day        44227 non-null  uint8  \n 17  review_scores_cleanliness              44227 non-null  float64\n 18  host_response_time_within an hour      44227 non-null  uint8  \n 19  review_scores_value                    44227 non-null  float64\n 20  host_total_listings_count              44227 non-null  float64\n 21  review_scores_checkin                  44227 non-null  float64\n 22  host_days                              44227 non-null  float64\n 23  host_response_time_missing             44227 non-null  uint8  \n 24  host_response_rate_num                 44227 non-null  float64\n 25  review_scores_communication            44227 non-null  float64\n 26  accommodates                           44227 non-null  float64\n 27  host_response_time_within a few hours  44227 non-null  uint8  \n 28  room_type_Hotel room                   44227 non-null  uint8  \n 29  bathrooms                              44227 non-null  float64\n 30  cancellation_policy_woe                44227 non-null  float64\n 31  property_type_woe                      44227 non-null  float64\n 32  neighbourhood_cleansed_woe             44227 non-null  float64\ndtypes: float64(22), uint8(11)\nmemory usage: 8.2 MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Since there are so many possibilities for an NLP model, we limit ourselves to trying 4 different model configurations on the text features. For all of them, we decide on some kind of LSTM architecture with embedding layer using Textvectorization.\nThe Keras Sequential API allows us to effectively train text feature models.\n\n1. Basic GRU\n2. LSTM\n3. CNN-LSTM\n4. Bidirectional LSTM\n\nFor all of these models, different hyperparameter configurations were tested. The number of hidden units inside the GRU units does not seem to make a big difference, so they are left at 128 for all the other models. The final activation functions are set to ReLU, since clap counts are never negative.\n\nWe refrain from using mean squared error loss, since it would make training performance difficult to judge.\nInstead, we could use the mean absolute error, but this loss can have difficulties finding a minimum because of its shape, especially at the high batch size of 64.\n\nWe therefore decide for log-cosh loss, which behaves very similarly to MAE, but does not suffer as much from the aforementioned negative property.","metadata":{}},{"cell_type":"code","source":"x_train_name = X_train['name']\nx_train_summary = X_train['summary']\nx_train_space = X_train['space']\nx_train_ngbr = X_train['neighborhood_overview']\nx_train_transit = X_train['transit']\nx_train_hr = X_train['house_rules']\nx_train_amenities = X_train['amenities']\nprint(len(x_train_name), len(x_train_summary), len(y_val))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:12:27.211715Z","iopub.execute_input":"2022-09-09T21:12:27.212068Z","iopub.status.idle":"2022-09-09T21:12:27.218884Z","shell.execute_reply.started":"2022-09-09T21:12:27.212032Z","shell.execute_reply":"2022-09-09T21:12:27.217940Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"44227 44227 11057\n","output_type":"stream"}]},{"cell_type":"code","source":"x_val_name = X_val['name']\nx_val_summary = X_val['summary']\nx_val_space = X_val['space']\nx_val_ngbr = X_val['neighborhood_overview']\nx_val_transit = X_val['transit']\nx_val_hr = X_val['house_rules']\nx_val_amenities = X_val['amenities']\nprint(len(x_val_name), len(x_val_summary), len(y_val))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:04.210126Z","iopub.execute_input":"2022-09-09T21:13:04.211503Z","iopub.status.idle":"2022-09-09T21:13:04.218528Z","shell.execute_reply.started":"2022-09-09T21:13:04.211458Z","shell.execute_reply":"2022-09-09T21:13:04.217522Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"11057 11057 11057\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 2.2.1 LSTM\n","metadata":{}},{"cell_type":"code","source":"def create_text_model(text_list):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(1,), dtype=tf.string))\n    vectorize_layer.adapt(text_list)\n    model.add(vectorize_layer)\n    model.add(layers.Embedding(input_dim=vocab_size, output_dim=emb_size))\n    model.add(layers.LSTM(rnn_units, return_sequences=False))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\ndef create_combined_model(X):\n    X = layers.Flatten()(X)\n    X = layers.Dense(1, activation=\"relu\")(X)\n    print(X.shape)\n    return X\n\n\ndef create_model():\n    \n    ### Initialize Input layers\n    input_desc = layers.Input(shape=(1,), dtype=tf.string)\n    input_ngbr = layers.Input(shape=(1,), dtype=tf.string)\n    input_name = layers.Input(shape=(1,), dtype=tf.string)\n    input_space = layers.Input(shape=(1,), dtype=tf.string)\n      \n    \n    ### Create Vectorisation models from text features\n    desc_model = create_text_model(x_train_summary)\n    ngbr_model = create_text_model(x_train_ngbr)\n    name_model = create_text_model(x_train_name)\n    space_model = create_text_model(x_train_space) \n    \n    ### Create Data flow\n    emb_desc = desc_model(input_desc)\n    emb_ngbr = ngbr_model(input_ngbr)\n    emb_name = desc_model(input_name)\n    emb_space = ngbr_model(input_space)\n    concat_combined = layers.Concatenate()([emb_desc,emb_ngbr,emb_name,emb_space])\n    print(concat_combined.shape)\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [input_desc, input_ngbr,input_name,input_space\n                                     ], outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),loss='mse', metrics=['mae'])\n    return model\n\n\nmodel = create_model()\nprint(model.summary())\n\nhistory = model.fit(\n    [x_train_summary, x_train_ngbr,x_train_name,x_train_space],\n    y_train,\n    validation_split=0.2,\n    epochs = 5,\n    batch_size = 32,\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T09:03:49.485860Z","iopub.execute_input":"2022-09-09T09:03:49.486538Z","iopub.status.idle":"2022-09-09T09:17:36.897147Z","shell.execute_reply.started":"2022-09-09T09:03:49.486505Z","shell.execute_reply":"2022-09-09T09:17:36.895647Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"(None, 4)\n(None, 1)\nModel: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_61 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_62 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_63 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_64 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nsequential_27 (Sequential)      (None, 1)            1117377     input_61[0][0]                   \n                                                                 input_63[0][0]                   \n__________________________________________________________________________________________________\nsequential_28 (Sequential)      (None, 1)            1117377     input_62[0][0]                   \n                                                                 input_64[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 4)            0           sequential_27[0][0]              \n                                                                 sequential_28[0][0]              \n                                                                 sequential_27[1][0]              \n                                                                 sequential_28[1][0]              \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 4)            0           concatenate_4[0][0]              \n__________________________________________________________________________________________________\ndense_35 (Dense)                (None, 1)            5           flatten_2[0][0]                  \n==================================================================================================\nTotal params: 2,234,759\nTrainable params: 2,234,759\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/5\n1106/1106 [==============================] - 167s 144ms/step - loss: 15714.8721 - mae: 93.3494 - val_loss: 14248.4678 - val_mae: 84.9432\nEpoch 2/5\n1106/1106 [==============================] - 157s 142ms/step - loss: 12570.0361 - mae: 75.7689 - val_loss: 11085.7881 - val_mae: 67.7259\nEpoch 3/5\n1106/1106 [==============================] - 155s 140ms/step - loss: 9681.6025 - mae: 61.9983 - val_loss: 8607.7920 - val_mae: 58.4386\nEpoch 4/5\n1106/1106 [==============================] - 155s 140ms/step - loss: 7834.5669 - mae: 56.7773 - val_loss: 7380.0518 - val_mae: 56.8051\nEpoch 5/5\n1106/1106 [==============================] - 155s 140ms/step - loss: 7129.7495 - mae: 57.3949 - val_loss: 7074.0220 - val_mae: 58.4773\n","output_type":"stream"}]},{"cell_type":"code","source":"preds_val = model.predict([x_val_summary,x_val_ngbr,x_val_name,x_val_space])\nprint(f\"MSE: {mean_squared_error(y_val, preds_val)}\")\nprint(f\"MAE: {mean_absolute_error(y_val, preds_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T09:19:13.434542Z","iopub.execute_input":"2022-09-09T09:19:13.434944Z","iopub.status.idle":"2022-09-09T09:19:30.966885Z","shell.execute_reply.started":"2022-09-09T09:19:13.434913Z","shell.execute_reply":"2022-09-09T09:19:30.965678Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"MSE: 7121.430842689313\nMAE: 58.98648451965283\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The model already starts overfitting at the fourth epoch. If this trend carries over to our final model, we should be prepared for using regularization techniques.","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.2 CNN-LSTM","metadata":{}},{"cell_type":"code","source":"def create_text_model(text_list):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(1,), dtype=tf.string))\n    vectorize_layer.adapt(text_list)\n    model.add(vectorize_layer)\n    model.add(layers.Embedding(input_dim=vocab_size, output_dim=emb_size))\n    model.add(layers.Conv1D(filters=16,kernel_size=5))\n    model.add(layers.AveragePooling1D(pool_size=2,strides=2))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.LSTM(rnn_units, return_sequences=True))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\ndef create_combined_model(X):\n    X = layers.Flatten()(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"relu\")(X)\n    print(X.shape)\n    return X\n\n\ndef create_model():\n    ### Initialize Input layers\n    input_desc = layers.Input(shape=(1,), dtype=tf.string)\n    input_ngbr = layers.Input(shape=(1,), dtype=tf.string)\n    input_name = layers.Input(shape=(1,), dtype=tf.string)\n    input_space = layers.Input(shape=(1,), dtype=tf.string)\n    \n    \n    ### Create Vectorisation models from text features\n    desc_model = create_text_model(x_train_summary)\n    ngbr_model = create_text_model(x_train_ngbr)\n    name_model = create_text_model(x_train_name)\n    space_model = create_text_model(x_train_space) \n    \n    ### Create Data flow\n    emb_desc = desc_model(input_desc)\n    emb_ngbr = ngbr_model(input_ngbr)\n    emb_name = desc_model(input_name)\n    emb_space = ngbr_model(input_space)\n    concat_combined = layers.Concatenate()([emb_desc,emb_ngbr,emb_name,emb_space])\n    print(concat_combined.shape)\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [input_desc, input_ngbr,input_name,input_space], outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                  loss=losses.LogCosh(),\n                  metrics=['mae'])\n    return model\n\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    [x_train_summary, x_train_ngbr,x_train_name,x_train_space],\n    y_train,\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks=[earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:11.179244Z","iopub.execute_input":"2022-09-09T21:13:11.179662Z","iopub.status.idle":"2022-09-09T21:24:50.046658Z","shell.execute_reply.started":"2022-09-09T21:13:11.179624Z","shell.execute_reply":"2022-09-09T21:24:50.045550Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2022-09-09 21:13:11.294505: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"(None, 248, 4)\n(None, 1)\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nsequential (Sequential)         (None, 248, 1)       1082385     input_1[0][0]                    \n                                                                 input_3[0][0]                    \n__________________________________________________________________________________________________\nsequential_1 (Sequential)       (None, 248, 1)       1082385     input_2[0][0]                    \n                                                                 input_4[0][0]                    \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 248, 4)       0           sequential[0][0]                 \n                                                                 sequential_1[0][0]               \n                                                                 sequential[1][0]                 \n                                                                 sequential_1[1][0]               \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 992)          0           concatenate[0][0]                \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 128)          127104      flatten[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 1)            129         dense_4[0][0]                    \n==================================================================================================\nTotal params: 2,292,003\nTrainable params: 2,292,003\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2022-09-09 21:13:34.575994: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"553/553 [==============================] - 61s 88ms/step - loss: 58.9103 - mae: 59.5982 - val_loss: 49.8242 - val_mae: 50.5105\nEpoch 2/30\n553/553 [==============================] - 46s 84ms/step - loss: 41.1054 - mae: 41.7884 - val_loss: 39.6246 - val_mae: 40.3072\nEpoch 3/30\n553/553 [==============================] - 47s 85ms/step - loss: 38.1375 - mae: 38.8195 - val_loss: 38.1029 - val_mae: 38.7852\nEpoch 4/30\n553/553 [==============================] - 48s 86ms/step - loss: 36.6997 - mae: 37.3809 - val_loss: 37.3446 - val_mae: 38.0260\nEpoch 5/30\n553/553 [==============================] - 48s 87ms/step - loss: 35.6255 - mae: 36.3063 - val_loss: 37.8951 - val_mae: 38.5772\nEpoch 6/30\n553/553 [==============================] - 48s 87ms/step - loss: 34.6473 - mae: 35.3280 - val_loss: 36.3255 - val_mae: 37.0073\nEpoch 7/30\n553/553 [==============================] - 48s 86ms/step - loss: 33.7037 - mae: 34.3834 - val_loss: 36.1271 - val_mae: 36.8077\nEpoch 8/30\n553/553 [==============================] - 48s 87ms/step - loss: 33.0818 - mae: 33.7621 - val_loss: 35.8511 - val_mae: 36.5327\nEpoch 9/30\n553/553 [==============================] - 48s 87ms/step - loss: 32.1782 - mae: 32.8573 - val_loss: 35.9111 - val_mae: 36.5925\nEpoch 10/30\n553/553 [==============================] - 48s 88ms/step - loss: 31.5094 - mae: 32.1884 - val_loss: 35.7915 - val_mae: 36.4726\nEpoch 11/30\n553/553 [==============================] - 48s 87ms/step - loss: 30.8273 - mae: 31.5056 - val_loss: 35.6280 - val_mae: 36.3091\nEpoch 12/30\n553/553 [==============================] - 48s 86ms/step - loss: 30.3596 - mae: 31.0370 - val_loss: 35.9277 - val_mae: 36.6099\nEpoch 13/30\n553/553 [==============================] - 47s 86ms/step - loss: 29.5938 - mae: 30.2714 - val_loss: 36.3524 - val_mae: 37.0344\nEpoch 14/30\n553/553 [==============================] - 48s 86ms/step - loss: 29.2280 - mae: 29.9064 - val_loss: 36.9227 - val_mae: 37.6053\n","output_type":"stream"}]},{"cell_type":"code","source":"preds_val = model.predict([x_val_summary,x_val_ngbr,x_val_name,x_val_space])\nprint(f\"MSE: {mean_squared_error(y_val, preds_val)}\")\nprint(f\"MAE: {mean_absolute_error(y_val, preds_val)}\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-09T12:43:46.063030Z","iopub.execute_input":"2022-09-09T12:43:46.063494Z","iopub.status.idle":"2022-09-09T12:44:49.355030Z","shell.execute_reply.started":"2022-09-09T12:43:46.063463Z","shell.execute_reply":"2022-09-09T12:44:49.353772Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"MSE: 3550.329466919092\nMAE: 36.57255240936569\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using CNN-LSTMs instead of LSTMs and fine-tuneable hyper-parameters like learning rate and epochs does already produce better performance. Especially notable is that this model starts to overfit much later than LSTM. ","metadata":{}},{"cell_type":"markdown","source":"#### 2.2.3 Bidirectional LSTM","metadata":{}},{"cell_type":"code","source":"def create_text_model(text_list):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(1,), dtype=tf.string))\n    vectorize_layer.adapt(text_list)\n    model.add(vectorize_layer)\n    model.add(layers.Embedding(input_dim=vocab_size, output_dim=emb_size))\n    model.add(layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True)))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\ndef create_combined_model(X):\n    X = layers.Flatten()(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"linear\")(X)\n    print(X.shape)\n    return X\n\n\ndef create_model():\n    \n    ### Initialize Input layers\n    input_desc = layers.Input(shape=(1,), dtype=tf.string)\n    input_ngbr = layers.Input(shape=(1,), dtype=tf.string)\n    input_name = layers.Input(shape=(1,), dtype=tf.string)\n    input_space = layers.Input(shape=(1,), dtype=tf.string)\n    \n    desc_model = create_text_model(x_train_summary)\n    ngbr_model = create_text_model(x_train_ngbr)\n    name_model = create_text_model(x_train_name)\n    space_model = create_text_model(x_train_space)\n    #     combined_model = create_combined_model()\n    \n    ### Create Data flow\n    emb_desc = desc_model(input_desc)\n    emb_ngbr = ngbr_model(input_ngbr)\n    emb_name = desc_model(input_name)\n    emb_space = ngbr_model(input_space)\n    concat_combined = layers.Concatenate()([emb_desc,emb_ngbr,emb_name,emb_space])\n    print(concat_combined.shape)\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [input_desc, input_ngbr,input_name,input_space], outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-5),\n                  loss=losses.LogCosh(),\n                  metrics=['mae'])\n    return model\n\n\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    [x_train_summary, x_train_ngbr,x_train_name,x_train_space],\n    y_train,\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks=[earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T11:30:28.787559Z","iopub.execute_input":"2022-09-09T11:30:28.789307Z","iopub.status.idle":"2022-09-09T12:23:36.651889Z","shell.execute_reply.started":"2022-09-09T11:30:28.789226Z","shell.execute_reply":"2022-09-09T12:23:36.650090Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"(None, 500, 4)\n(None, 1)\nModel: \"model_10\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_140 (InputLayer)          [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_141 (InputLayer)          [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_142 (InputLayer)          [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_143 (InputLayer)          [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nsequential_64 (Sequential)      (None, 500, 1)       1234753     input_140[0][0]                  \n                                                                 input_142[0][0]                  \n__________________________________________________________________________________________________\nsequential_65 (Sequential)      (None, 500, 1)       1234753     input_141[0][0]                  \n                                                                 input_143[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_12 (Concatenate)    (None, 500, 4)       0           sequential_64[0][0]              \n                                                                 sequential_65[0][0]              \n                                                                 sequential_64[1][0]              \n                                                                 sequential_65[1][0]              \n__________________________________________________________________________________________________\nflatten_10 (Flatten)            (None, 2000)         0           concatenate_12[0][0]             \n__________________________________________________________________________________________________\ndense_81 (Dense)                (None, 128)          256128      flatten_10[0][0]                 \n__________________________________________________________________________________________________\ndense_82 (Dense)                (None, 1)            129         dense_81[0][0]                   \n==================================================================================================\nTotal params: 2,725,763\nTrainable params: 2,725,763\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 199s 335ms/step - loss: 58.4336 - mae: 59.1213 - val_loss: 47.3484 - val_mae: 48.0347\nEpoch 2/30\n553/553 [==============================] - 184s 333ms/step - loss: 40.1674 - mae: 40.8499 - val_loss: 38.4984 - val_mae: 39.1797\nEpoch 3/30\n553/553 [==============================] - 183s 330ms/step - loss: 37.0414 - mae: 37.7229 - val_loss: 38.7469 - val_mae: 39.4316\nEpoch 4/30\n553/553 [==============================] - 184s 333ms/step - loss: 35.6290 - mae: 36.3101 - val_loss: 36.5768 - val_mae: 37.2575\nEpoch 5/30\n553/553 [==============================] - 186s 337ms/step - loss: 33.8780 - mae: 34.5588 - val_loss: 36.5425 - val_mae: 37.2234\nEpoch 6/30\n553/553 [==============================] - 186s 337ms/step - loss: 33.0805 - mae: 33.7602 - val_loss: 35.6164 - val_mae: 36.2985\nEpoch 7/30\n553/553 [==============================] - 187s 338ms/step - loss: 31.9476 - mae: 32.6270 - val_loss: 34.9941 - val_mae: 35.6750\nEpoch 8/30\n553/553 [==============================] - 186s 336ms/step - loss: 31.1155 - mae: 31.7944 - val_loss: 35.0527 - val_mae: 35.7330\nEpoch 9/30\n553/553 [==============================] - 187s 338ms/step - loss: 30.3193 - mae: 30.9977 - val_loss: 35.3286 - val_mae: 36.0086\nEpoch 10/30\n553/553 [==============================] - 187s 337ms/step - loss: 29.8218 - mae: 30.4998 - val_loss: 36.0865 - val_mae: 36.7694\nEpoch 11/30\n553/553 [==============================] - 186s 336ms/step - loss: 28.9246 - mae: 29.6019 - val_loss: 35.1315 - val_mae: 35.8131\nEpoch 12/30\n553/553 [==============================] - 187s 337ms/step - loss: 28.2570 - mae: 28.9332 - val_loss: 35.7304 - val_mae: 36.4127\nEpoch 13/30\n553/553 [==============================] - 186s 336ms/step - loss: 28.0283 - mae: 28.7047 - val_loss: 35.0301 - val_mae: 35.7125\nEpoch 14/30\n553/553 [==============================] - 186s 337ms/step - loss: 27.9010 - mae: 28.5779 - val_loss: 35.3960 - val_mae: 36.0773\nEpoch 15/30\n553/553 [==============================] - 186s 336ms/step - loss: 26.8681 - mae: 27.5437 - val_loss: 35.0262 - val_mae: 35.7074\nEpoch 16/30\n553/553 [==============================] - 186s 336ms/step - loss: 26.0833 - mae: 26.7580 - val_loss: 36.2633 - val_mae: 36.9470\nEpoch 17/30\n553/553 [==============================] - 186s 337ms/step - loss: 25.7229 - mae: 26.3976 - val_loss: 35.0089 - val_mae: 35.6910\n","output_type":"stream"}]},{"cell_type":"code","source":"preds_val = model.predict([x_val_summary,x_val_ngbr,x_val_name,x_val_space])\nprint(f\"MSE: {mean_squared_error(y_val, preds_val)}\")\nprint(f\"MAE: {mean_absolute_error(y_val, preds_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T12:25:29.046264Z","iopub.execute_input":"2022-09-09T12:25:29.046888Z","iopub.status.idle":"2022-09-09T12:26:09.364026Z","shell.execute_reply.started":"2022-09-09T12:25:29.046846Z","shell.execute_reply":"2022-09-09T12:26:09.362562Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"MSE: 3421.79965495661\nMAE: 34.791717146613166\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Full model architecture","metadata":{}},{"cell_type":"code","source":"def create_ann():\n    model = models.Sequential()\n    model.add(layers.Dense(16, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(8, activation='relu'))\n    return model\n\ndef create_text_model(text_list):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(1,), dtype=tf.string))\n    vectorize_layer.adapt(text_list)\n    model.add(vectorize_layer)\n    model.add(layers.Embedding(input_dim=vocab_size, output_dim=emb_size))\n    model.add(layers.Conv1D(filters=16,kernel_size=5))\n    model.add(layers.AveragePooling1D(pool_size=2,strides=2))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.LSTM(rnn_units, return_sequences=True))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\ndef create_combined_model(X):\n    X = layers.Dropout(0.2)(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    # X = layers.Dense(64, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"relu\")(X)\n    print(X.shape)\n    return X\n\n\n\ndef create_model():\n    \n    ### Initialize Input layers\n    input_desc = layers.Input(shape=(1,), dtype=tf.string)\n    input_ngbr = layers.Input(shape=(1,), dtype=tf.string)\n    input_name = layers.Input(shape=(1,), dtype=tf.string)\n    input_space = layers.Input(shape=(1,), dtype=tf.string)\n    input_numeric = tf.keras.Input(shape=(x_train_num_cols.shape[1],), dtype=tf.float64, name=\"numeric\")\n    \n    ### Create Vectorisation models from text features\n    desc_model = create_text_model(x_train_summary)\n    ngbr_model = create_text_model(x_train_ngbr)\n    name_model = create_text_model(x_train_name)\n    space_model = create_text_model(x_train_space)\n#     combined_model = create_combined_model()\n    \n    ### Create Data flow\n    emb_desc = desc_model(input_desc)\n    emb_ngbr = ngbr_model(input_ngbr)\n    emb_name = desc_model(input_name)\n    emb_space = ngbr_model(input_space)\n    numeric_layers = create_ann()(input_numeric)\n    concat_combined = layers.Concatenate()([emb_desc,emb_ngbr,emb_name,emb_space])\n    print(concat_combined.shape)\n    concat_combined = layers.Flatten()(concat_combined)\n    concat_combined = layers.Concatenate()([concat_combined, numeric_layers])\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [input_desc, input_ngbr,input_name,input_space,input_numeric], outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                  loss=losses.LogCosh(),\n                  metrics=['mae'])\n    return model\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    [x_train_summary, x_train_ngbr,x_train_name,x_train_space,x_train_num_cols],\n    y,\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks=[earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:01:42.169104Z","iopub.execute_input":"2022-09-09T15:01:42.169929Z","iopub.status.idle":"2022-09-09T15:07:28.393966Z","shell.execute_reply.started":"2022-09-09T15:01:42.169869Z","shell.execute_reply":"2022-09-09T15:07:28.393025Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(None, 248, 4)\n(None, 1)\nModel: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_13 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_14 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_15 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_16 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nsequential_5 (Sequential)       (None, 248, 1)       1082385     input_13[0][0]                   \n                                                                 input_15[0][0]                   \n__________________________________________________________________________________________________\nsequential_6 (Sequential)       (None, 248, 1)       1082385     input_14[0][0]                   \n                                                                 input_16[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 248, 4)       0           sequential_5[0][0]               \n                                                                 sequential_6[0][0]               \n                                                                 sequential_5[1][0]               \n                                                                 sequential_6[1][0]               \n__________________________________________________________________________________________________\nnumeric (InputLayer)            [(None, 33)]         0                                            \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 992)          0           concatenate_2[0][0]              \n__________________________________________________________________________________________________\nsequential_9 (Sequential)       (None, 8)            680         numeric[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 1000)         0           flatten_1[0][0]                  \n                                                                 sequential_9[0][0]               \n__________________________________________________________________________________________________\ndropout_11 (Dropout)            (None, 1000)         0           concatenate_3[0][0]              \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 128)          128128      dropout_11[0][0]                 \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 1)            129         dense_14[0][0]                   \n==================================================================================================\nTotal params: 2,293,707\nTrainable params: 2,293,707\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 54s 87ms/step - loss: 61.1333 - mae: 61.8217 - val_loss: 55.7633 - val_mae: 56.4523\nEpoch 2/30\n553/553 [==============================] - 46s 84ms/step - loss: 56.1596 - mae: 56.8474 - val_loss: 55.7633 - val_mae: 56.4520\nEpoch 3/30\n553/553 [==============================] - 47s 84ms/step - loss: 56.0932 - mae: 56.7813 - val_loss: 56.0320 - val_mae: 56.7201\nEpoch 4/30\n553/553 [==============================] - 47s 84ms/step - loss: 56.1215 - mae: 56.8095 - val_loss: 55.7305 - val_mae: 56.4177\nEpoch 5/30\n553/553 [==============================] - 47s 85ms/step - loss: 56.0318 - mae: 56.7193 - val_loss: 55.7261 - val_mae: 56.4123\nEpoch 6/30\n553/553 [==============================] - 47s 84ms/step - loss: 55.9504 - mae: 56.6379 - val_loss: 55.7847 - val_mae: 56.4732\nEpoch 7/30\n553/553 [==============================] - 47s 84ms/step - loss: 55.5592 - mae: 56.2466 - val_loss: 56.3533 - val_mae: 57.0409\n","output_type":"stream"}]},{"cell_type":"code","source":"preds_val = model.predict([x_val_summary,x_val_ngbr,x_val_name,x_val_space,x_val_num_cols])\nprint(f\"MSE: {mean_squared_error(y_val, preds_val)}\")\nprint(f\"MAE: {mean_absolute_error(y_val, preds_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:08:01.076557Z","iopub.execute_input":"2022-09-09T15:08:01.076978Z","iopub.status.idle":"2022-09-09T15:08:31.396127Z","shell.execute_reply.started":"2022-09-09T15:08:01.076942Z","shell.execute_reply":"2022-09-09T15:08:31.395150Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"MSE: 7756.347374607242\nMAE: 57.25877130243978\n","output_type":"stream"}]},{"cell_type":"markdown","source":"It can be seen from all the above models that the self-training of word embeddings doesn't perfom well both in terms of MAE and also results in overfitting of train data.","metadata":{}}]}