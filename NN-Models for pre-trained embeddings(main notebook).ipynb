{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Advanced Data Analytics for Management Support - Assignment Submission","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n    1. Introduction\n    2. Data Loading and Cleaning\n    3. Feature Analysis \n        3.1 Target Distribution\n        3.2 Date features\n    4. Model Selection\n        4.1 Data Preparation\n        4.2 Models(structured data)\n            4.2.1 Linear Regression\n            4.2.2 Random Forest\n            4.2.3 XGBoost\n            4.2.4 Adaboost Regressor\n            4.2.4 FNN\n        4.3 RNN Architecture (unstructured data)\n            4.3.1 GRU\n            4.3.2 LSTM\n            4.3.3 Bidirectional LSTM\n            4.3.4 CNN-LSTM\n        4.4 Full Model Architecture\n    5. Application to Test Set\n    6. Conclusion\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"The task of this assignment is to predict the price of propertied hosted on an online marketplace for accommodation rental called as Airbnb, based on different webscraped features like the location, number of rooms, property type, texts with the listing description, and rental price per night.The main focus hereby lies on building an NN-based model that predicts the price of listings in the unseen dataset based on both text and tabular data.\n\nIn the following, we analyze the train and test data, alter some of the features, as well as create new ones. Afterwards, different modeling approaches are considered and an NLP pipeline is chosen which is then applied to our test data.","metadata":{}},{"cell_type":"code","source":"!pip install textstat","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:18.288203Z","iopub.execute_input":"2022-09-09T21:13:18.289584Z","iopub.status.idle":"2022-09-09T21:13:28.492905Z","shell.execute_reply.started":"2022-09-09T21:13:18.289536Z","shell.execute_reply":"2022-09-09T21:13:28.491141Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: textstat in /opt/conda/lib/python3.7/site-packages (0.7.3)\nRequirement already satisfied: pyphen in /opt/conda/lib/python3.7/site-packages (from textstat) (0.13.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\nimport datetime\nimport time\nimport textstat\nfrom bs4 import BeautifulSoup\nfrom collections import Counter\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom gensim.models import KeyedVectors\nfrom gensim.models.keyedvectors import Word2VecKeyedVectors\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, concatenate, Dense, Embedding, LSTM, GRU, Bidirectional, BatchNormalization, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.initializers import Constant\nfrom tensorflow.keras import activations, losses\nfrom keras.callbacks import EarlyStopping\nimport xgboost as xgb\nfrom bs4 import BeautifulSoup\nimport emoji as emot\nimport nltk  \nnltk.download('omw-1.4')\n# When running this notebook for the first time, you have to download some NLTK packages. To do so, simply uncomment the next lines\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\nfrom sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV ,cross_val_score, train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom tensorflow.keras import layers, models, optimizers, losses\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom numpy import mean\nfrom numpy import absolute\nfrom numpy import sqrt\nfrom sklearn.experimental import enable_halving_search_cv \nfrom sklearn.model_selection import HalvingGridSearchCV\n\nimport tensorflow as tf\nimport pickle\nimport string\nimport statistics\nimport math\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:29.991497Z","iopub.execute_input":"2022-09-09T21:13:29.991918Z","iopub.status.idle":"2022-09-09T21:13:30.074655Z","shell.execute_reply.started":"2022-09-09T21:13:29.991879Z","shell.execute_reply":"2022-09-09T21:13:30.073479Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Data Loading and Cleaning ","metadata":{}},{"cell_type":"markdown","source":"To make the code modular, data cleaning and feature engineering for tabular data and unstructured data has been done in a separate notebooks (see Data_cleaning_tabular.ipnyb and Data_cleaning_text.ipnyb).\n\nThe following steps are performed for cleaning and feature engineering of tabular data:\n\n1. Checking and handling the data for null values \n2. Checking for duplicated values in the dataset\n3. Handling categorical and nominal variables( consists of creating dummy variables, binning via weight of evidence encoding, and scaling the continous variables)\n4. Creating new features(features related to date and time are utilized to generate new features appropriate for modeling)\n5. Feature Selection to find the best combination of features based on the statistical performance\n\nThe cleaned tabular data is then stored in the pickle file, which can then further be used to perform text cleaning. \n\nThe following steps are performed in text cleaning:\n\n1. Removing whitespace (tabs, newlines).Newline indicators are removed (\"\\n\" and \"\\xa0\")\n2. remove the punctuation, upper casing and words that include non-alphanumeric characters.\n3. Stopwords are filtered out\n4. html content is removed for a more sophisticated cleaning of text\n5. The words are lemmatized\n\nWe would be using pickle file containing the pre-processed tabular (numerical) data for further text pre-processing and modeling tasks in this notebook.\n\nThe cleaned numerical features for both data sets are loaded in the following manner:","metadata":{}},{"cell_type":"code","source":"train = pd.read_pickle('../input/airbnb-last-version-numerical-data/x_train.pkl')\ntest = pd.read_pickle('../input/airbnb-last-version-numerical-data/x_test.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:33.906160Z","iopub.execute_input":"2022-09-09T21:13:33.906649Z","iopub.status.idle":"2022-09-09T21:13:36.382475Z","shell.execute_reply.started":"2022-09-09T21:13:33.906609Z","shell.execute_reply":"2022-09-09T21:13:36.381075Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()/55284 * 100","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:38.304101Z","iopub.execute_input":"2022-09-09T21:13:38.304502Z","iopub.status.idle":"2022-09-09T21:13:38.362262Z","shell.execute_reply.started":"2022-09-09T21:13:38.304468Z","shell.execute_reply":"2022-09-09T21:13:38.361156Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"host_is_superhost                         0.000000\nreviews_per_month                         0.000000\nroom_type_Private room                    0.000000\nbed_type_Real Bed                         0.000000\nbed_type_Pull-out Sofa                    0.000000\nbedrooms                                  0.000000\nbed_type_Couch                            0.000000\nbeds                                      0.000000\nroom_type_Shared room                     0.000000\nreview_scores_location                    0.000000\nguests_included                           0.000000\nbed_type_Futon                            0.000000\nreview_scores_rating                      0.000000\nhouse_rules                              22.755228\nsummary                                   2.852543\nhost_identity_verified                    0.000000\nhost_has_profile_pic                      0.000000\nreview_scores_accuracy                    0.000000\nhost_response_time_within a day           0.000000\nspace                                    16.382679\nreview_scores_cleanliness                 0.000000\npicture_url                               0.000000\nlisting_id                                0.000000\nhost_since                                0.000000\nhost_response_rate                       17.314232\nneighbourhood                             0.155560\nhost_response_time_within an hour         0.000000\nname                                      0.018088\nreview_scores_value                       0.000000\nhost_total_listings_count                 0.000000\namenities                                 0.000000\nexperiences_offered                       0.000000\nreview_scores_checkin                     0.000000\nhost_days                                 0.000000\nhost_response_time_missing                0.000000\nhost_response_rate_num                    0.000000\nreview_scores_communication               0.000000\ntransit                                  19.303958\naccommodates                              0.000000\nhost_response_time_within a few hours     0.000000\nneighborhood_overview                    19.085088\nroom_type_Hotel room                      0.000000\nbathrooms                                 0.000000\ndescription                               1.705738\ncancellation_policy_woe                   0.000000\nproperty_type_woe                         0.010853\nneighbourhood_cleansed_woe                0.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"test['property_type_woe'].fillna(0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:41.188865Z","iopub.execute_input":"2022-09-09T21:13:41.190043Z","iopub.status.idle":"2022-09-09T21:13:41.200047Z","shell.execute_reply.started":"2022-09-09T21:13:41.190003Z","shell.execute_reply":"2022-09-09T21:13:41.198648Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"These cleaned train and test datasets obtained after tabular data preprocessing(see \"Data_cleaning_tabular.ipnyb\") are further processed for text cleaning as seen in the following section, \"Data Cleaning(unstructured data)\".","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Data Cleaning(Unstructured Data)","metadata":{}},{"cell_type":"code","source":"def remove_whitespace(text):\n    \"\"\" Function to remove whitespace (tabs, newlines). \"\"\"\n    return ' '.join(text.split())","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:10:03.561768Z","iopub.execute_input":"2022-09-09T13:10:03.562194Z","iopub.status.idle":"2022-09-09T13:10:03.568026Z","shell.execute_reply.started":"2022-09-09T13:10:03.562158Z","shell.execute_reply":"2022-09-09T13:10:03.566996Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def convert_emoticons(text):\n    \"\"\" Function to convert emoticons into a text that reflects their meaning. \"\"\"\n    EMOTICONS = emot.EMOTICONS()\n    for i in EMOTICONS:\n        text = text.replace(i, EMOTICONS[i])\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:14.284957Z","iopub.status.idle":"2022-09-09T13:09:14.285370Z","shell.execute_reply.started":"2022-09-09T13:09:14.285179Z","shell.execute_reply":"2022-09-09T13:09:14.285198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punctuation_and_casing(text):\n    \"\"\"\n    Function to remove the punctuation, upper casing and words that include\n    non-alphanumeric characters.\n    \"\"\"\n    chars = '!\\\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n    text = text.translate(str.maketrans(chars, ' ' * len(chars)))\n    return ' '.join([word.lower() for word in text.split() if word.isalpha()])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:14.758016Z","iopub.execute_input":"2022-09-09T13:09:14.758458Z","iopub.status.idle":"2022-09-09T13:09:14.765354Z","shell.execute_reply.started":"2022-09-09T13:09:14.758423Z","shell.execute_reply":"2022-09-09T13:09:14.764442Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nenglish_stopwords = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:16.543813Z","iopub.execute_input":"2022-09-09T13:09:16.544244Z","iopub.status.idle":"2022-09-09T13:09:17.839233Z","shell.execute_reply.started":"2022-09-09T13:09:16.544210Z","shell.execute_reply":"2022-09-09T13:09:17.837862Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def remove_stopwords(text):\n    \"\"\" Function to remove stopwords. \"\"\"\n    return ' '.join([word for word in str(text).split() if word not in english_stopwords])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:18.597275Z","iopub.execute_input":"2022-09-09T13:09:18.598213Z","iopub.status.idle":"2022-09-09T13:09:18.604750Z","shell.execute_reply.started":"2022-09-09T13:09:18.598161Z","shell.execute_reply":"2022-09-09T13:09:18.603835Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import wordnet\n\ndef get_wordnet_pos(word):\n    \"\"\"Helper function that calls the POS tagger for an input word and return a code that can be used for lemmatization\"\"\"\n    # Extract the first letter of the POS tag (see the above example to understand the output coming from pos_tag)\n    tag = nltk.pos_tag([word])[0][1][0].upper()  \n    # Dictionary to map these letters to wordnet codes that the lemmatizer understands\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n    return tag_dict.get(tag, wordnet.NOUN)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:25.695925Z","iopub.execute_input":"2022-09-09T13:09:25.696490Z","iopub.status.idle":"2022-09-09T13:09:25.705047Z","shell.execute_reply.started":"2022-09-09T13:09:25.696444Z","shell.execute_reply":"2022-09-09T13:09:25.704131Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize_words(text, **kwargs):\n    \"\"\" Function to lemmatize words. \"\"\"\n    return ' '.join([lemmatizer.lemmatize(word, **kwargs) for word in text.split()])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:26.972191Z","iopub.execute_input":"2022-09-09T13:09:26.972649Z","iopub.status.idle":"2022-09-09T13:09:26.978785Z","shell.execute_reply.started":"2022-09-09T13:09:26.972610Z","shell.execute_reply":"2022-09-09T13:09:26.977612Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(documents):\n    \"\"\"\n    Function for standard NLP pre-processing including removal of html tags,\n    whitespaces, non-alphanumeric characters, and stopwords. Emoticons are\n    converted to text that reflects their meaning. Words are subject to\n    lemmatization using their POS tags.\n    \"\"\"\n    cleaned_text = []  # our output will be a list of documents\n    lemmatizer = WordNetLemmatizer()\n    \n    print('Processing input array with {} elements...'.format(documents.shape[0]))\n    counter = 0\n    \n    for doc in documents:\n        text = BeautifulSoup(doc).get_text() # remove html content\n        text = remove_whitespace(text) # remove whitespaces\n        text = remove_punctuation_and_casing(text) # remove punctuation and casing\n        text = remove_stopwords(text) # remove stopwords\n        text = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text.split()]) # lemmatize each word\n        \n        cleaned_text.append(text)\n\n        if (counter > 0 and counter % 50 == 0):\n            print('Processed {} documents'.format(counter))\n            \n        counter += 1\n        \n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:09:28.561638Z","iopub.execute_input":"2022-09-09T13:09:28.562051Z","iopub.status.idle":"2022-09-09T13:09:28.571028Z","shell.execute_reply.started":"2022-09-09T13:09:28.562018Z","shell.execute_reply":"2022-09-09T13:09:28.569543Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"raw","source":"Before passing the text columns in the \"text_cleaning\" process, we need to handle the null values in the text columns. We start by replacing the null values in the text columns with empty strings.","metadata":{}},{"cell_type":"code","source":"train['neighborhood_overview'].fillna('',inplace=True)\ntrain['space'].fillna('',inplace=True)\ntrain['summary'].fillna('',inplace=True)\ntrain['name'].fillna('',inplace=True)\ntrain['transit'].fillna('',inplace=True)\ntrain['house_rules'].fillna('',inplace=True)\ntrain['amenities'].fillna('',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:11:03.201864Z","iopub.execute_input":"2022-09-09T13:11:03.202302Z","iopub.status.idle":"2022-09-09T13:11:03.263602Z","shell.execute_reply.started":"2022-09-09T13:11:03.202269Z","shell.execute_reply":"2022-09-09T13:11:03.262201Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train['name'] = text_cleaning(train['name'])\ntrain['summary'] = text_cleaning(train['summary'])\ntrain['space'] = text_cleaning(train['space'])\n#train['description'] = text_cleaning(train['description'])\ntrain['experiences_offered'] = text_cleaning(train['experiences_offered'])\ntrain['neighborhood_overview'] = text_cleaning(train['neighborhood_overview'])\ntrain['transit'] = text_cleaning(train['transit'])\ntrain['house_rules'] = text_cleaning(train['house_rules'])\ntrain['amenities'] = text_cleaning(train['amenities'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['neighborhood_overview'].fillna('',inplace=True)\ntest['space'].fillna('',inplace=True)\ntest['summary'].fillna('',inplace=True)\ntest['name'].fillna('',inplace=True)\ntest['transit'].fillna('',inplace=True)\ntest['house_rules'].fillna('',inplace=True)\ntest['amenities'].fillna('',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T13:49:27.638937Z","iopub.execute_input":"2022-09-09T13:49:27.639792Z","iopub.status.idle":"2022-09-09T13:49:27.679216Z","shell.execute_reply.started":"2022-09-09T13:49:27.639746Z","shell.execute_reply":"2022-09-09T13:49:27.677720Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test['name'] = text_cleaning(test.name)\ntest['summary'] = text_cleaning(test.summary)\ntest['space'] = text_cleaning(test.space)\n#train['description'] = text_cleaning(train['description'])\ntest['experiences_offered'] = text_cleaning(test.experiences_offered)\ntest['neighborhood_overview'] = text_cleaning(test.neighborhood_overview)\ntest['transit'] = text_cleaning(test.transit)\ntest['house_rules'] = text_cleaning(test.house_rules)\ntest['amenities'] = text_cleaning(test.amenities)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_pickle('x_train_text_for_pre_trained_word_emb.pkl')\ntest.to_pickle('x_test_text_for_pre_trained_word_emb.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T14:15:15.792504Z","iopub.execute_input":"2022-09-09T14:15:15.792914Z","iopub.status.idle":"2022-09-09T14:15:16.425417Z","shell.execute_reply.started":"2022-09-09T14:15:15.792883Z","shell.execute_reply":"2022-09-09T14:15:16.424359Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Saving the cleaned train and test data (both tabular and unstructured features) in a pickle to avoid re-running the cleaning pipeline again.","metadata":{}},{"cell_type":"code","source":"train = pd.read_pickle('../input/final-text-cleaned/x_train_text_for_pre_trained_word_emb.pkl')\ntest = pd.read_pickle('../input/final-text-cleaned/x_test_text_for_pre_trained_word_emb.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:13:48.628877Z","iopub.execute_input":"2022-09-09T21:13:48.629478Z","iopub.status.idle":"2022-09-09T21:13:50.554302Z","shell.execute_reply.started":"2022-09-09T21:13:48.629440Z","shell.execute_reply":"2022-09-09T21:13:50.553197Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Loop through the words and update a counter keeping track of word counts\nimport collections\n\nword_counter = collections.Counter()\nfor r in train[\"neighborhood_overview\"]:\n    for w in r.split():        \n        word_counter.update({w: 1})  ","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:29:51.739427Z","iopub.execute_input":"2022-09-09T17:29:51.739858Z","iopub.status.idle":"2022-09-09T17:29:54.293318Z","shell.execute_reply.started":"2022-09-09T17:29:51.739815Z","shell.execute_reply":"2022-09-09T17:29:54.292218Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Query the top most frequent words\ntop_n = 10\nword_counter.most_common(top_n)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:29:54.295071Z","iopub.execute_input":"2022-09-09T17:29:54.295419Z","iopub.status.idle":"2022-09-09T17:29:54.307315Z","shell.execute_reply.started":"2022-09-09T17:29:54.295382Z","shell.execute_reply":"2022-09-09T17:29:54.306143Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"[('walk', 32816),\n ('london', 27948),\n ('restaurant', 22357),\n ('minute', 21971),\n ('park', 20956),\n ('area', 17560),\n ('shop', 16559),\n ('street', 16379),\n ('away', 13269),\n ('market', 12593)]"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3. Feature Analysis","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Target Distribution","metadata":{}},{"cell_type":"markdown","source":"Here we use the original(uncleaned train and test) datasets for feature analysis purpose.","metadata":{}},{"cell_type":"code","source":"train_orig = pd.read_csv(\"../input/airbnb/train.csv\", sep=\",\", encoding=\"utf-8\")\ntest_orig = pd.read_csv(\"../input/airbnb/test.csv\", sep=\",\", encoding=\"utf-8\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T19:58:22.108243Z","iopub.execute_input":"2022-09-09T19:58:22.108826Z","iopub.status.idle":"2022-09-09T19:58:27.199852Z","shell.execute_reply.started":"2022-09-09T19:58:22.108757Z","shell.execute_reply":"2022-09-09T19:58:27.198765Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# Show target distribution\nplt.hist(train.price)\nplt.xlabel('Price')\nplt.title('Price distribution')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-09-09T19:52:53.552078Z","iopub.execute_input":"2022-09-09T19:52:53.552455Z","iopub.status.idle":"2022-09-09T19:52:53.757062Z","shell.execute_reply.started":"2022-09-09T19:52:53.552423Z","shell.execute_reply":"2022-09-09T19:52:53.756083Z"},"trusted":true},"execution_count":97,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"The price of the properties are mostly towards the lower side, with only a few properties with high prices. These high prices cannot be treated as outliers since there might exist valid reasons for these high prices. ","metadata":{}},{"cell_type":"markdown","source":"## 3.2 Date Feature","metadata":{}},{"cell_type":"code","source":"train_orig[\"host_since\"] = train_orig[\"host_since\"].astype(\"datetime64[ns]\")\ntrain_orig[\"host_since\"].fillna(pd.to_datetime('2015-05-21'),inplace = True)\ntrain_orig['host_days'] = (datetime.datetime.today() - train_orig['host_since'])//np.timedelta64(1,'D')   \ntrain_orig['host_days'] = train_orig['host_days']/365","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:02:17.778665Z","iopub.execute_input":"2022-09-09T20:02:17.779251Z","iopub.status.idle":"2022-09-09T20:02:17.821404Z","shell.execute_reply.started":"2022-09-09T20:02:17.779178Z","shell.execute_reply":"2022-09-09T20:02:17.820402Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"train_orig['year'] = pd.DatetimeIndex(train_orig['host_since']).year\ntrain_orig['month'] = pd.DatetimeIndex(train_orig['host_since']).month","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:07:39.001353Z","iopub.execute_input":"2022-09-09T20:07:39.001734Z","iopub.status.idle":"2022-09-09T20:07:39.022318Z","shell.execute_reply.started":"2022-09-09T20:07:39.001702Z","shell.execute_reply":"2022-09-09T20:07:39.021396Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"test_orig['year'] = pd.DatetimeIndex(test_orig['host_since']).year\ntest_orig['month'] = pd.DatetimeIndex(test_orig['host_since']).month","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:10:48.636350Z","iopub.execute_input":"2022-09-09T20:10:48.636862Z","iopub.status.idle":"2022-09-09T20:10:48.673283Z","shell.execute_reply.started":"2022-09-09T20:10:48.636817Z","shell.execute_reply":"2022-09-09T20:10:48.672317Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"plt.subplots(1, 2, figsize=(15, 4))\nplt.subplot(1, 2, 1)\nplt.title(\"Train Distribution\")\npd.Series(train_orig.year.value_counts()).plot.bar();\nplt.subplot(1, 2, 2)\nplt.title(\"Test Distribution\")\npd.Series(test_orig.year.value_counts()).plot.bar();","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:11:09.951377Z","iopub.execute_input":"2022-09-09T20:11:09.951739Z","iopub.status.idle":"2022-09-09T20:11:10.340937Z","shell.execute_reply.started":"2022-09-09T20:11:09.951708Z","shell.execute_reply":"2022-09-09T20:11:10.340059Z"},"trusted":true},"execution_count":112,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"It is seen that most of the properties have been listed on airbnb in the year 2015 and almost none in 2008. ","metadata":{}},{"cell_type":"code","source":"train_orig.groupby(\"year\")[\"price\"].agg(\"mean\").sort_values().plot.bar();","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:12:54.138153Z","iopub.execute_input":"2022-09-09T20:12:54.138576Z","iopub.status.idle":"2022-09-09T20:12:54.377823Z","shell.execute_reply.started":"2022-09-09T20:12:54.138540Z","shell.execute_reply":"2022-09-09T20:12:54.376740Z"},"trusted":true},"execution_count":114,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"This shows that as the time passed the prices of the properties being listed on Airbnb decreased. This feature seems like a strong predictor in further analysis.","metadata":{}},{"cell_type":"markdown","source":"# 4. Model Selection","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Data preparation using Pre-trained word embeddings","metadata":{}},{"cell_type":"markdown","source":"Before we proceed with benchmarking and modeling, we need to make sure that our text features are in appropriate format to be fed into NLP algorithms. The first question that pops up when dealing with Deep Learning models is whether to work with pre-trained word embeddings or embedding layer like TextVectorization using keras. Similar to most problems in AI, there might not be a universally correct answer to this question that works in every scenario. Therefore, we perform experimentation based on these two types of embeddings to study their effects on the performance of the NLP models. \n\nIn order to make the code modular we create two modeling notebooks:\n1. w2v_pretrained_modeling_airbnb.ipynb\n2. Self_trained_emb_modeling_airbnb.ipynb\n\nw2v_pretrained_modeling_airbnb.ipynb i.e. the current notebook covers the modeling the data using pre-trained word embeddings. Additionally, we need to load our pre-trained embeddings and make some changes to the text to be able to unlock their full potential.\n\nFor our embeddings, we decide to go with 100-dimensional wiki2vec embeddings from https://wikipedia2vec.github.io/wikipedia2vec/pretrained/\n\nLooking at the \"description\" feature we can see that it is a combination of summary,space and neighborhood_overview text features. In order to avoid redundant information in the pipeline, we chose to drop the description feature from the analysis. Also, since \"description\" feature is relatively long as compared to summary,space and neighborhood_overview features, the context might get lost in dense layers of the NLP models. ","metadata":{}},{"cell_type":"code","source":"import datetime\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:14:01.054106Z","iopub.execute_input":"2022-09-09T21:14:01.054537Z","iopub.status.idle":"2022-09-09T21:14:01.058905Z","shell.execute_reply.started":"2022-09-09T21:14:01.054499Z","shell.execute_reply":"2022-09-09T21:14:01.057685Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Load wiki2vec embeddings:\nstart = time.time()\nwiki2vec = KeyedVectors.load_word2vec_format('../input/enwiki-100/enwiki_20180420_100d.txt')\nend = time.time()\nprint(f\"Loaded wiki2vec embeddings in {end - start} seconds.\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:14:08.037302Z","iopub.execute_input":"2022-09-09T21:14:08.038017Z","iopub.status.idle":"2022-09-09T21:19:12.796737Z","shell.execute_reply.started":"2022-09-09T21:14:08.037977Z","shell.execute_reply":"2022-09-09T21:19:12.795002Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Loaded wiki2vec embeddings in 304.7469847202301 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"wiki2vec.most_similar(\"walk\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:19:40.009587Z","iopub.execute_input":"2022-09-09T15:19:40.009982Z","iopub.status.idle":"2022-09-09T15:19:41.010979Z","shell.execute_reply.started":"2022-09-09T15:19:40.009948Z","shell.execute_reply":"2022-09-09T15:19:41.009982Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[('walking', 0.7974323034286499),\n ('walks', 0.7364681363105774),\n ('stroll', 0.7279573082923889),\n ('walked', 0.7097617387771606),\n ('go', 0.6963003873825073),\n ('ride', 0.6943541169166565),\n ('traipse', 0.6928747892379761),\n ('fillingfir', 0.6851910948753357),\n ('wander', 0.6751559376716614),\n ('fireroad', 0.674683690071106)]"},"metadata":{}}]},{"cell_type":"markdown","source":"Splitting the training data into train and validation sets for analyzing the performance of different NLP models.","metadata":{}},{"cell_type":"code","source":"X_train_nlp, X_test_nlp, y_train_nlp, y_test_nlp = train_test_split(train.drop(\"price\",axis = 1), train['price'], test_size=0.20, random_state=111)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:19:37.595529Z","iopub.execute_input":"2022-09-09T21:19:37.596062Z","iopub.status.idle":"2022-09-09T21:19:37.869704Z","shell.execute_reply.started":"2022-09-09T21:19:37.596022Z","shell.execute_reply":"2022-09-09T21:19:37.868718Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train_nlp.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:19:39.737535Z","iopub.execute_input":"2022-09-09T21:19:39.737965Z","iopub.status.idle":"2022-09-09T21:19:39.990963Z","shell.execute_reply.started":"2022-09-09T21:19:39.737934Z","shell.execute_reply":"2022-09-09T21:19:39.990069Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 44227 entries, 45478 to 12116\nData columns (total 47 columns):\n #   Column                                 Non-Null Count  Dtype         \n---  ------                                 --------------  -----         \n 0   host_is_superhost                      44227 non-null  float64       \n 1   reviews_per_month                      44227 non-null  float64       \n 2   room_type_Private room                 44227 non-null  uint8         \n 3   bed_type_Real Bed                      44227 non-null  uint8         \n 4   bed_type_Pull-out Sofa                 44227 non-null  uint8         \n 5   bedrooms                               44227 non-null  float64       \n 6   bed_type_Couch                         44227 non-null  uint8         \n 7   beds                                   44227 non-null  float64       \n 8   room_type_Shared room                  44227 non-null  uint8         \n 9   review_scores_location                 44227 non-null  float64       \n 10  guests_included                        44227 non-null  float64       \n 11  bed_type_Futon                         44227 non-null  uint8         \n 12  review_scores_rating                   44227 non-null  float64       \n 13  house_rules                            44227 non-null  object        \n 14  summary                                44227 non-null  object        \n 15  host_identity_verified                 44227 non-null  float64       \n 16  host_has_profile_pic                   44227 non-null  float64       \n 17  review_scores_accuracy                 44227 non-null  float64       \n 18  host_response_time_within a day        44227 non-null  uint8         \n 19  space                                  44227 non-null  object        \n 20  review_scores_cleanliness              44227 non-null  float64       \n 21  picture_url                            44227 non-null  object        \n 22  listing_id                             44227 non-null  object        \n 23  host_since                             44227 non-null  datetime64[ns]\n 24  host_response_rate                     29926 non-null  object        \n 25  neighbourhood                          44106 non-null  object        \n 26  host_response_time_within an hour      44227 non-null  uint8         \n 27  name                                   44227 non-null  object        \n 28  review_scores_value                    44227 non-null  float64       \n 29  host_total_listings_count              44227 non-null  float64       \n 30  amenities                              44227 non-null  object        \n 31  experiences_offered                    44227 non-null  object        \n 32  review_scores_checkin                  44227 non-null  float64       \n 33  host_days                              44227 non-null  float64       \n 34  host_response_time_missing             44227 non-null  uint8         \n 35  host_response_rate_num                 44227 non-null  float64       \n 36  review_scores_communication            44227 non-null  float64       \n 37  transit                                44227 non-null  object        \n 38  accommodates                           44227 non-null  float64       \n 39  host_response_time_within a few hours  44227 non-null  uint8         \n 40  neighborhood_overview                  44227 non-null  object        \n 41  room_type_Hotel room                   44227 non-null  uint8         \n 42  bathrooms                              44227 non-null  float64       \n 43  description                            42842 non-null  object        \n 44  cancellation_policy_woe                44227 non-null  float64       \n 45  property_type_woe                      44227 non-null  float64       \n 46  neighbourhood_cleansed_woe             44227 non-null  float64       \ndtypes: datetime64[ns](1), float64(22), object(13), uint8(11)\nmemory usage: 12.9+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Tokenized objects and embedding matrices are initialized separately for each text feature. To truncate the text features optimally we determine the length of the tokens for different percentiles. Furthermore, we pick the maximum length which falls under the 99.7 percentile for all the text columns. This allows us to use text features mostly without truncation. Additonally,this makes the length optimal by reducing the amount of padding needed for the text features.","metadata":{}},{"cell_type":"code","source":"sumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['name'].tolist())))\nprint(\"name\",np.percentile(sumamry,[25,50,75,90,99.7],))\n\nsumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['summary'].tolist())))\nprint(\"summary\",np.percentile(sumamry,[25,50,75,90,99.7],))\n\nsumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['space'].tolist())))\nprint(\"space\",np.percentile(sumamry,[25,50,75,90,99.7],))\n\nsumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['neighborhood_overview'].tolist())))\nprint(\"neighborhood_overview\",np.percentile(sumamry,[25,50,75,90,99.7],))\n\nsumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['transit'].tolist())))\nprint(\"transit\",np.percentile(sumamry,[25,50,75,90,99.7],))\n\nsumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['house_rules'].tolist())))\nprint(\"house_rules\",np.percentile(sumamry,[25,50,75,90,99.7],))\n\nsumamry = np.array(list(map(lambda x:len(x.split()), X_train_nlp['amenities'].tolist())))\nprint(\"amenities\",np.percentile(sumamry,[25,50,75,90,99.7],))","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:19:44.179937Z","iopub.execute_input":"2022-09-09T21:19:44.180320Z","iopub.status.idle":"2022-09-09T21:19:44.750144Z","shell.execute_reply.started":"2022-09-09T21:19:44.180288Z","shell.execute_reply":"2022-09-09T21:19:44.748875Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"name [4. 5. 6. 7. 8.]\nsummary [ 23.  35.  47.  52. 101.]\nspace [  0.  21.  57.  96. 116.]\nneighborhood_overview [  0.  16.  42.  82. 109.]\ntransit [  0.  14.  32.  56. 109.]\nhouse_rules [ 0.  3. 17. 44. 98.]\namenities [21. 31. 45. 58. 99.]\n","output_type":"stream"}]},{"cell_type":"code","source":"from gensim.models import KeyedVectors\nfrom gensim.models.keyedvectors import Word2VecKeyedVectors\n\ndef get_embedding_matrix(tokenizer, pretrain, vocab_size):\n    '''\n        Helper function to construct an embedding matrix for\n        the focal corpus based on some pre-trained embeddings.\n    '''\n\n    dim = 0\n    if isinstance(pretrain, KeyedVectors) or isinstance(pretrain, Word2VecKeyedVectors):\n        dim = pretrain.vector_size\n    elif isinstance(pretrain, dict):\n        dim = next(iter(pretrain.values())).shape[0]  # get embedding of an arbitrary word\n    else:\n        raise Exception('{} is not supported'.format(type(pretrain)))\n\n    # Initialize embedding matrix\n    emb_mat = np.zeros((vocab_size, dim))\n\n    # There will be some words in our corpus for which we lack a pre-trained embedding.\n    # In this tutorial, we will simply use a vector of zeros for such words. We also keep\n    # track of the words to do some debugging if needed\n    oov_words = []\n    # Below we use the tokenizer object that created our task vocabulary. This is crucial to ensure\n    # that the position of a words in our embedding matrix corresponds to its index in our integer\n    # encoded input data\n    for word, i in tokenizer.word_index.items():\n        # try-catch together with a zero-initilaized embedding matrix achieves our rough fix for oov words\n        try:\n            emb_mat[i] = pretrain[word]\n        except:\n            oov_words.append(word)\n    print('Created embedding matrix of shape {}'.format(emb_mat.shape))\n    print('Encountered {} out-of-vocabulary words.'.format(len(oov_words)))\n    return emb_mat, oov_words","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:19:48.225467Z","iopub.execute_input":"2022-09-09T21:19:48.225874Z","iopub.status.idle":"2022-09-09T21:19:48.236647Z","shell.execute_reply.started":"2022-09-09T21:19:48.225839Z","shell.execute_reply":"2022-09-09T21:19:48.235414Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def tokenizer(train_text,test_text,max_length):\n    tokenizer_text = Tokenizer(oov_token=1, filters='!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower=False)\n    tokenizer_text.fit_on_texts(train_text)\n    NUM_WORDS_TEXT = len(tokenizer_text.word_index) + 1\n    x_train = tokenizer_text.texts_to_sequences(train_text)\n    MAX_TEXT_LENGTH = max_length\n    x_train_pad = pad_sequences(x_train, MAX_TEXT_LENGTH)\n    #encode and pad test data\n    x_test = tokenizer_text.texts_to_sequences(test_text)\n    x_test_pad = pad_sequences(x_test, MAX_TEXT_LENGTH)\n    wiki_weights, _ = get_embedding_matrix(tokenizer_text, wiki2vec, NUM_WORDS_TEXT)\n    return x_train_pad,x_test_pad,wiki_weights,NUM_WORDS_TEXT   ","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:19:53.619713Z","iopub.execute_input":"2022-09-09T21:19:53.620327Z","iopub.status.idle":"2022-09-09T21:19:53.626720Z","shell.execute_reply.started":"2022-09-09T21:19:53.620291Z","shell.execute_reply":"2022-09-09T21:19:53.625935Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Below we create tokenizer objects and embedding matrices for training the model on our train dataset and analyzing the performace of different models for our the training data.","metadata":{}},{"cell_type":"code","source":"X_tr_name,X_test_name,wiki_weights_name,NUM_WORDS_NAME = tokenizer(X_train_nlp.name,X_test_nlp.name,8)\nX_tr_summary,X_test_summary,wiki_weights_summary,NUM_WORDS_SUMMARY = tokenizer(X_train_nlp.summary,X_test_nlp.summary,101)\nX_tr_space,X_test_space,wiki_weights_space,NUM_WORDS_SPACE = tokenizer(X_train_nlp.space,X_test_nlp.space,116)\n#X_tr_experiences,X_test_experiences,wiki_weights_experiences = tokenizer(X_train_nlp.experiences_offered,X_test_nlp.experiences_offered,692)\nX_tr_ngbr,X_test_ngbr,wiki_weights_ngbr,NUM_WORDS_NGBR = tokenizer(X_train_nlp.neighborhood_overview,X_test_nlp.neighborhood_overview,109)\nX_tr_transit,X_test_transit,wiki_weights_transit,NUM_WORDS_TRANSIT = tokenizer(X_train_nlp.transit,X_test_nlp.transit,109)\nX_tr_hr,X_test_hr,wiki_weights_hr,NUM_WORDS_HR = tokenizer(X_train_nlp.house_rules,X_test_nlp.house_rules,98)\nX_tr_amenities,X_test_amenities,wiki_weights_amenities,NUM_WORDS_AMENITIES = tokenizer(X_train_nlp.amenities,X_test_nlp.amenities,99)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:19:56.337375Z","iopub.execute_input":"2022-09-09T21:19:56.338164Z","iopub.status.idle":"2022-09-09T21:20:14.932145Z","shell.execute_reply.started":"2022-09-09T21:19:56.338127Z","shell.execute_reply":"2022-09-09T21:20:14.929882Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Created embedding matrix of shape (5410, 100)\nEncountered 849 out-of-vocabulary words.\nCreated embedding matrix of shape (16410, 100)\nEncountered 3030 out-of-vocabulary words.\nCreated embedding matrix of shape (17044, 100)\nEncountered 2480 out-of-vocabulary words.\nCreated embedding matrix of shape (17938, 100)\nEncountered 2344 out-of-vocabulary words.\nCreated embedding matrix of shape (10104, 100)\nEncountered 1594 out-of-vocabulary words.\nCreated embedding matrix of shape (8527, 100)\nEncountered 951 out-of-vocabulary words.\nCreated embedding matrix of shape (269, 100)\nEncountered 0 out-of-vocabulary words.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In order to train our full model arcitecture we reinitialize the the tokenizer objects and embedding matrices for the unseen data using our whole train dataset as seen below. ","metadata":{}},{"cell_type":"code","source":"tr_name,test_name,wiki_weights_name_tr,NUM_WORDS_NAME_tr = tokenizer(train.name,test.name,8)\ntr_summary,test_summary,wiki_weights_summary_tr,NUM_WORDS_SUMMARY_tr = tokenizer(train.summary,test.summary,101)\ntr_space,test_space,wiki_weights_space_tr,NUM_WORDS_SPACE_tr = tokenizer(train.space,test.space,116)\n#X_tr_experiences,X_test_experiences,wiki_weights_experiences = tokenizer(X_train_nlp.experiences_offered,X_test_nlp.experiences_offered,692)\ntr_ngbr,test_ngbr,wiki_weights_ngbr_tr,NUM_WORDS_NGBR_tr = tokenizer(train.neighborhood_overview,test.neighborhood_overview,109)\ntr_transit,test_transit,wiki_weights_transit_tr,NUM_WORDS_TRANSIT_tr = tokenizer(train.transit,test.transit,109)\ntr_hr,test_hr,wiki_weights_hr_tr,NUM_WORDS_HR_tr = tokenizer(train.house_rules,test.house_rules,98)\ntr_amenities,test_amenities,wiki_weights_amenities_tr,NUM_WORDS_AMENITIES_tr = tokenizer(train.amenities,test.amenities,99)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:48:41.219039Z","iopub.execute_input":"2022-09-09T17:48:41.219582Z","iopub.status.idle":"2022-09-09T17:49:04.335662Z","shell.execute_reply.started":"2022-09-09T17:48:41.219539Z","shell.execute_reply":"2022-09-09T17:49:04.334637Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"Created embedding matrix of shape (6019, 100)\nEncountered 1023 out-of-vocabulary words.\nCreated embedding matrix of shape (18327, 100)\nEncountered 3772 out-of-vocabulary words.\nCreated embedding matrix of shape (18747, 100)\nEncountered 2990 out-of-vocabulary words.\nCreated embedding matrix of shape (19596, 100)\nEncountered 2775 out-of-vocabulary words.\nCreated embedding matrix of shape (11030, 100)\nEncountered 1860 out-of-vocabulary words.\nCreated embedding matrix of shape (9293, 100)\nEncountered 1113 out-of-vocabulary words.\nCreated embedding matrix of shape (271, 100)\nEncountered 0 out-of-vocabulary words.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4.2 Models(structured data)","metadata":{}},{"cell_type":"code","source":"x_train_num_cols = X_train_nlp.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\nx_val_num_cols = X_test_nlp.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:20:18.723082Z","iopub.execute_input":"2022-09-09T21:20:18.723502Z","iopub.status.idle":"2022-09-09T21:20:18.739744Z","shell.execute_reply.started":"2022-09-09T21:20:18.723469Z","shell.execute_reply":"2022-09-09T21:20:18.738662Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.1 Linear Regression","metadata":{}},{"cell_type":"code","source":"regression = LinearRegression(normalize=True)\nregression.fit(x_train_num_cols, y_train_nlp)\n\nprediction = regression.predict(x_val_num_cols)\n\nprint(f\"R2: {regression.score(x_val_num_cols, y_test_nlp)}\")\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:35:54.787282Z","iopub.execute_input":"2022-09-09T17:35:54.787639Z","iopub.status.idle":"2022-09-09T17:35:54.857163Z","shell.execute_reply.started":"2022-09-09T17:35:54.787609Z","shell.execute_reply":"2022-09-09T17:35:54.856170Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"R2: 0.5270095346909986\nMSE: 3197.702435741736\nMAE: 35.790265794959716\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\nIf you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n\nfrom sklearn.pipeline import make_pipeline\n\nmodel = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n\nIf you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n\nkwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\nmodel.fit(X, y, **kwargs)\n\n\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This is already a very nice result from Linear regression which can serve as a benchmark performance for the other models for tabular and text data.","metadata":{}},{"cell_type":"markdown","source":"### 4.2.2 Random Forest","metadata":{}},{"cell_type":"markdown","source":"In order to determine the best hyperparamaters for the ensemble methods we apply the HalvingGridSearchCV algorithm to fine tune the models. This will also help in validating the performance of the model.","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\n\nparam_grid = {'n_estimators': [500,1000],\n              'max_samples' : [0.1,0.5]              \n             }\n\nsearch = HalvingGridSearchCV(rf, param_grid,\n                            random_state=0, cv=5, scoring='neg_root_mean_squared_error').fit(x_train_num_cols, y_train_nlp)\nsearch.best_params_  \n#{'max_samples': 0.5, 'n_estimators': 500}","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:26:35.377927Z","iopub.execute_input":"2022-09-09T20:26:35.378822Z","iopub.status.idle":"2022-09-09T20:52:20.718480Z","shell.execute_reply.started":"2022-09-09T20:26:35.378762Z","shell.execute_reply":"2022-09-09T20:52:20.717490Z"},"trusted":true},"execution_count":119,"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"{'max_samples': 0.5, 'n_estimators': 500}"},"metadata":{}}]},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=500, max_depth = None, max_samples = 0.5, random_state=111, verbose=0, n_jobs=10)\nrf.fit(x_train_num_cols, y_train_nlp)\n\nprediction = rf.predict(x_val_num_cols)\n\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:54:27.903882Z","iopub.execute_input":"2022-09-09T20:54:27.904460Z","iopub.status.idle":"2022-09-09T20:55:31.481466Z","shell.execute_reply.started":"2022-09-09T20:54:27.904425Z","shell.execute_reply":"2022-09-09T20:55:31.479737Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"MSE: 2499.7121170632586\nMAE: 30.639093778865416\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As expected, Random forest regressor outperforms the linear regression model.","metadata":{}},{"cell_type":"markdown","source":"### 4.2.3 XGB Boost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:39:36.763635Z","iopub.execute_input":"2022-09-09T17:39:36.764535Z","iopub.status.idle":"2022-09-09T17:39:36.770039Z","shell.execute_reply.started":"2022-09-09T17:39:36.764487Z","shell.execute_reply":"2022-09-09T17:39:36.768832Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"xgb_regress = xgb.XGBRegressor()\n\nparam_grid = {'n_estimators': [500,1000],\n              'learning_rate' : [0.1,0.05]              \n             }\n\nsearch = HalvingGridSearchCV(xgb_regress, param_grid,\n                            random_state=0, cv=5, scoring='neg_root_mean_squared_error').fit(x_train_num_cols, y_train_nlp)\nsearch.best_params_  \n#{'max_samples': 0.05, 'n_estimators': 1000}","metadata":{"execution":{"iopub.status.busy":"2022-09-09T20:55:53.964714Z","iopub.execute_input":"2022-09-09T20:55:53.965126Z","iopub.status.idle":"2022-09-09T21:07:14.003589Z","shell.execute_reply.started":"2022-09-09T20:55:53.965093Z","shell.execute_reply":"2022-09-09T21:07:14.002582Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.05, 'n_estimators': 1000}"},"metadata":{}}]},{"cell_type":"code","source":"xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 1, learning_rate = 0.05,\n                max_depth=2, alpha=20, n_estimators = 1000)\nxg_reg.fit(x_train_num_cols,y_train_nlp)\n\nprediction = xg_reg.predict(x_val_num_cols)\n\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:40:02.751222Z","iopub.execute_input":"2022-09-09T17:40:02.751587Z","iopub.status.idle":"2022-09-09T17:40:29.415023Z","shell.execute_reply.started":"2022-09-09T17:40:02.751556Z","shell.execute_reply":"2022-09-09T17:40:29.414144Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"MSE: 2712.630927912829\nMAE: 31.980587851104183\n","output_type":"stream"}]},{"cell_type":"markdown","source":"XGB Boost does outperform the Linear regression but fails to surpass the random forest regressor, potentially because of overfitting issue.","metadata":{}},{"cell_type":"markdown","source":"### 4.2.4 AdaBoost Regressor","metadata":{}},{"cell_type":"code","source":"adaregress = AdaBoostRegressor()\n\nparam_grid = {'n_estimators': [500,1000],\n              'learning_rate' : [0.1,0.5,1.0]              \n             }\n\nsearch = HalvingGridSearchCV(adaregress, param_grid,\n                            random_state=0, cv=5, scoring='neg_root_mean_squared_error').fit(x_train_num_cols, y_train_nlp)\nsearch.best_params_  \n#{'max_samples': 0.1, 'n_estimators': 1000}","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:07:45.355369Z","iopub.execute_input":"2022-09-09T21:07:45.355939Z","iopub.status.idle":"2022-09-09T21:10:11.478194Z","shell.execute_reply.started":"2022-09-09T21:07:45.355879Z","shell.execute_reply":"2022-09-09T21:10:11.477032Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.1, 'n_estimators': 1000}"},"metadata":{}}]},{"cell_type":"code","source":"ada_reg = AdaBoostRegressor(learning_rate = 0.1,n_estimators = 1000,random_state=0)\nada_reg.fit(x_train_num_cols,y_train_nlp)\n\nprediction = ada_reg.predict(x_val_num_cols)\n\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:41:19.607160Z","iopub.execute_input":"2022-09-09T17:41:19.607522Z","iopub.status.idle":"2022-09-09T17:41:36.194597Z","shell.execute_reply.started":"2022-09-09T17:41:19.607491Z","shell.execute_reply":"2022-09-09T17:41:36.192826Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"MSE: 5249.059538733441\nMAE: 59.882034305683106\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Suprisingly Adacost Regressor performs worst among all the ensemble and linear regression model. This might be because the price is skewed towards lower values,which indicates inability of adacost regressor to predict very high values in this case.","metadata":{}},{"cell_type":"markdown","source":"### 4.2.5 FNN","metadata":{}},{"cell_type":"code","source":"input_numeric = tf.keras.Input(shape=(x_train_num_cols.shape[1],), dtype=tf.float64, name=\"numeric\")\noutput_numeric = layers.Dense(128, activation='relu')(input_numeric)\noutput_numeric = layers.Dense(64, activation='relu')(output_numeric)\n#output_numeric = layers.Dropout(0.2)(output_numeric)\noutput_numeric = layers.Dense(32, activation=\"relu\")(output_numeric)\noutput = layers.Dense(1, activation=\"linear\")(output_numeric)\n\n\n## Finalize the model with input and output flow\nmodel = tf.keras.Model(inputs = [\n                                input_numeric\n                                ], \n                            outputs = output)\nprint(model.summary())\nmodel.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n            loss=losses.LogCosh(), metrics=['mae'])\n\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    [x_train_num_cols],\n    y_train_nlp,\n    validation_split=0.2,\n    epochs = 40,\n    batch_size = 64,\n    callbacks=[earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T21:20:23.973013Z","iopub.execute_input":"2022-09-09T21:20:23.973489Z","iopub.status.idle":"2022-09-09T21:21:24.640315Z","shell.execute_reply.started":"2022-09-09T21:20:23.973450Z","shell.execute_reply":"2022-09-09T21:21:24.639454Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-09-09 21:20:24.055087: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nnumeric (InputLayer)         [(None, 33)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               4352      \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_2 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 14,721\nTrainable params: 14,721\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"},{"name":"stderr","text":"2022-09-09 21:20:24.313054: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n553/553 [==============================] - 2s 3ms/step - loss: 82.0097 - mae: 82.6994 - val_loss: 48.9585 - val_mae: 49.6448\nEpoch 2/40\n553/553 [==============================] - 2s 3ms/step - loss: 41.2559 - mae: 41.9405 - val_loss: 37.0922 - val_mae: 37.7753\nEpoch 3/40\n553/553 [==============================] - 2s 3ms/step - loss: 35.6199 - mae: 36.3025 - val_loss: 34.2955 - val_mae: 34.9767\nEpoch 4/40\n553/553 [==============================] - 1s 3ms/step - loss: 33.8786 - mae: 34.5597 - val_loss: 33.1315 - val_mae: 33.8121\nEpoch 5/40\n553/553 [==============================] - 1s 3ms/step - loss: 33.0331 - mae: 33.7139 - val_loss: 32.6102 - val_mae: 33.2911\nEpoch 6/40\n553/553 [==============================] - 1s 3ms/step - loss: 32.5502 - mae: 33.2303 - val_loss: 32.1905 - val_mae: 32.8710\nEpoch 7/40\n553/553 [==============================] - 1s 3ms/step - loss: 32.2599 - mae: 32.9399 - val_loss: 31.9016 - val_mae: 32.5821\nEpoch 8/40\n553/553 [==============================] - 1s 3ms/step - loss: 32.0573 - mae: 32.7376 - val_loss: 31.6793 - val_mae: 32.3588\nEpoch 9/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.9015 - mae: 32.5816 - val_loss: 31.5426 - val_mae: 32.2224\nEpoch 10/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.7657 - mae: 32.4455 - val_loss: 31.4347 - val_mae: 32.1147\nEpoch 11/40\n553/553 [==============================] - 2s 3ms/step - loss: 31.6453 - mae: 32.3242 - val_loss: 31.3193 - val_mae: 31.9983\nEpoch 12/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.5401 - mae: 32.2196 - val_loss: 31.2354 - val_mae: 31.9157\nEpoch 13/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.4558 - mae: 32.1348 - val_loss: 31.1726 - val_mae: 31.8529\nEpoch 14/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.3658 - mae: 32.0453 - val_loss: 31.1181 - val_mae: 31.7990\nEpoch 15/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.2993 - mae: 31.9782 - val_loss: 31.0299 - val_mae: 31.7105\nEpoch 16/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.2326 - mae: 31.9112 - val_loss: 30.9956 - val_mae: 31.6760\nEpoch 17/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.1712 - mae: 31.8503 - val_loss: 30.9404 - val_mae: 31.6217\nEpoch 18/40\n553/553 [==============================] - 2s 3ms/step - loss: 31.1045 - mae: 31.7834 - val_loss: 30.9005 - val_mae: 31.5821\nEpoch 19/40\n553/553 [==============================] - 1s 3ms/step - loss: 31.0560 - mae: 31.7351 - val_loss: 30.8384 - val_mae: 31.5198\nEpoch 20/40\n553/553 [==============================] - 2s 3ms/step - loss: 31.0052 - mae: 31.6845 - val_loss: 30.7998 - val_mae: 31.4815\nEpoch 21/40\n553/553 [==============================] - 2s 3ms/step - loss: 30.9580 - mae: 31.6367 - val_loss: 30.8016 - val_mae: 31.4814\nEpoch 22/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.9116 - mae: 31.5906 - val_loss: 30.7289 - val_mae: 31.4097\nEpoch 23/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.8652 - mae: 31.5439 - val_loss: 30.7196 - val_mae: 31.4001\nEpoch 24/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.8345 - mae: 31.5125 - val_loss: 30.6510 - val_mae: 31.3324\nEpoch 25/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.7887 - mae: 31.4668 - val_loss: 30.7133 - val_mae: 31.3928\nEpoch 26/40\n553/553 [==============================] - 2s 3ms/step - loss: 30.7647 - mae: 31.4433 - val_loss: 30.5837 - val_mae: 31.2644\nEpoch 27/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.7140 - mae: 31.3925 - val_loss: 30.5721 - val_mae: 31.2528\nEpoch 28/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.6762 - mae: 31.3548 - val_loss: 30.5755 - val_mae: 31.2553\nEpoch 29/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.6554 - mae: 31.3337 - val_loss: 30.5109 - val_mae: 31.1920\nEpoch 30/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.6227 - mae: 31.3009 - val_loss: 30.4842 - val_mae: 31.1653\nEpoch 31/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.5887 - mae: 31.2668 - val_loss: 30.4547 - val_mae: 31.1359\nEpoch 32/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.5567 - mae: 31.2347 - val_loss: 30.4339 - val_mae: 31.1146\nEpoch 33/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.5381 - mae: 31.2161 - val_loss: 30.4513 - val_mae: 31.1315\nEpoch 34/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.5056 - mae: 31.1835 - val_loss: 30.3900 - val_mae: 31.0705\nEpoch 35/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.4649 - mae: 31.1430 - val_loss: 30.3859 - val_mae: 31.0665\nEpoch 36/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.4301 - mae: 31.1080 - val_loss: 30.3763 - val_mae: 31.0571\nEpoch 37/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.4066 - mae: 31.0848 - val_loss: 30.3127 - val_mae: 30.9930\nEpoch 38/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.3848 - mae: 31.0625 - val_loss: 30.2891 - val_mae: 30.9688\nEpoch 39/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.3611 - mae: 31.0385 - val_loss: 30.2700 - val_mae: 30.9494\nEpoch 40/40\n553/553 [==============================] - 1s 3ms/step - loss: 30.3393 - mae: 31.0173 - val_loss: 30.2691 - val_mae: 30.9480\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict([x_val_num_cols])\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:44:36.046695Z","iopub.execute_input":"2022-09-09T17:44:36.047094Z","iopub.status.idle":"2022-09-09T17:44:36.439008Z","shell.execute_reply.started":"2022-09-09T17:44:36.047060Z","shell.execute_reply":"2022-09-09T17:44:36.437095Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"MSE: 3002.6311047996437\nMAE: 31.25935934421608\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The performance of the Feed Forward neural network on the tabular data also crosses the benchmark set by the linear regression model. FNNs performance is comparable to both random forest and XGB boost in our case. Although, it doesn't seem to win the benchmark performance for tabular data.\n\nBoth MSE and MAE-wise it looks like the Random Forest regressor is winning the benchmark. This gives us a baseline of what to expect from the NLP models. ","metadata":{}},{"cell_type":"markdown","source":"## 4.3 RNN Architecture (unstructured data)","metadata":{}},{"cell_type":"markdown","source":"Since there are so many possibilities for an NLP model, we limit ourselves to trying 4 different model configurations on the text features. For all of them, we decide on some kind of LSTM architecture with embedding layer using Textvectorization.\nThe Keras Sequential API allows us to effectively train text feature models.\n\n1. Basic GRU\n2. LSTM\n3. CNN-LSTM\n4. Bidirectional LSTM\n\nFor all of these models, different hyperparameter configurations were tested. The number of hidden units inside the GRU units does not seem to make a big difference, so they are left at 128 for all the other models. The final activation functions are set to ReLU, since price of peroperties are never negative.\n\nWe refrain from using mean squared error loss, since it would make training performance difficult to judge.\nInstead, we could use the mean absolute error, but this loss can have difficulties finding a minimum because of its shape.\n\nWe therefore decide for log-cosh loss, which behaves very similarly to MAE, but does not suffer as much from the aforementioned negative property.\n\nAdditonally, we would also make comparison between the performance of the models for both types of embeddings i.e. pret-trained and self-trained embeddings using Textvectorization.(see Self_trained_emb_modeling_airbnb.ipnyb).","metadata":{}},{"cell_type":"markdown","source":"### 4.3.1 Basic GRU","metadata":{}},{"cell_type":"code","source":"input_summary = Input(shape=(101, ))\ninput_name = Input(shape=(8, ))\ninput_ngbr = Input(shape=(109, ))\ninput_space = Input(shape=(116, ))\n\n# summary\nsummary_embeddings = Embedding(input_dim=NUM_WORDS_SUMMARY, output_dim=100, input_length=101,embeddings_initializer=Constant(wiki_weights_summary),\n                     trainable=True)(input_summary)\nGRU_summary = GRU(100)(summary_embeddings)\ndense_summary = Dense(1, activation=\"relu\")(GRU_summary)\n\n# name\nname_embeddings = Embedding(input_dim=NUM_WORDS_NAME, output_dim=100, input_length=8,embeddings_initializer=Constant(wiki_weights_name),\n                     trainable=True)(input_name)\nGRU_name = GRU(100)(name_embeddings)\ndense_name = Dense(1, activation=\"relu\")(GRU_name)\n\n# neighbourhood overview\nngbr_embeddings = Embedding(input_dim=NUM_WORDS_NGBR, output_dim=100, input_length=109,embeddings_initializer=Constant(wiki_weights_ngbr),\n                     trainable=True)(input_ngbr)\nGRU_ngbr = GRU(100)(ngbr_embeddings)\ndense_ngbr = Dense(1, activation=\"relu\")(GRU_ngbr)\n\n# space\nspace_embeddings = Embedding(input_dim=NUM_WORDS_SPACE, output_dim=100, input_length=116,embeddings_initializer=Constant(wiki_weights_space),\n                     trainable=True)(input_space)\nGRU_space = GRU(100)(space_embeddings)\ndense_space = Dense(1, activation=\"relu\")(GRU_space)\n\n# Concatenate\noutput_layer = concatenate([dense_summary,dense_name, dense_ngbr,dense_space])\n#dense_full = Dense(1024, activation=\"relu\")(concat)\n#dense_full = Dense(512, activation=\"relu\")(dense_full)\ndense_full = Dense(256, activation=\"relu\")(output_layer)\noutput_layer = Dense(1, activation=\"relu\")(dense_full)\n\nmodel = Model(inputs=[input_summary,input_name, input_ngbr,input_space], outputs=output_layer)\nmodel.compile(loss=losses.LogCosh(), optimizer=\"adam\", metrics=[\"mae\"])\n\nprint(model.summary())\ncallbacks = [EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n\nstory = model.fit([X_tr_summary,X_tr_name, X_tr_ngbr,X_tr_space], y_train_nlp, epochs=30, verbose=1, batch_size=64, \n          validation_split=0.2, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T16:25:46.664026Z","iopub.execute_input":"2022-09-09T16:25:46.664949Z","iopub.status.idle":"2022-09-09T16:27:40.906651Z","shell.execute_reply.started":"2022-09-09T16:25:46.664911Z","shell.execute_reply":"2022-09-09T16:27:40.905516Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Model: \"model_11\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_48 (InputLayer)           [(None, 101)]        0                                            \n__________________________________________________________________________________________________\ninput_49 (InputLayer)           [(None, 8)]          0                                            \n__________________________________________________________________________________________________\ninput_50 (InputLayer)           [(None, 109)]        0                                            \n__________________________________________________________________________________________________\ninput_51 (InputLayer)           [(None, 116)]        0                                            \n__________________________________________________________________________________________________\nembedding_43 (Embedding)        (None, 101, 100)     1641000     input_48[0][0]                   \n__________________________________________________________________________________________________\nembedding_44 (Embedding)        (None, 8, 100)       541000      input_49[0][0]                   \n__________________________________________________________________________________________________\nembedding_45 (Embedding)        (None, 109, 100)     1793800     input_50[0][0]                   \n__________________________________________________________________________________________________\nembedding_46 (Embedding)        (None, 116, 100)     1704400     input_51[0][0]                   \n__________________________________________________________________________________________________\ngru_10 (GRU)                    (None, 100)          60600       embedding_43[0][0]               \n__________________________________________________________________________________________________\ngru_11 (GRU)                    (None, 100)          60600       embedding_44[0][0]               \n__________________________________________________________________________________________________\ngru_12 (GRU)                    (None, 100)          60600       embedding_45[0][0]               \n__________________________________________________________________________________________________\ngru_13 (GRU)                    (None, 100)          60600       embedding_46[0][0]               \n__________________________________________________________________________________________________\ndense_72 (Dense)                (None, 1)            101         gru_10[0][0]                     \n__________________________________________________________________________________________________\ndense_73 (Dense)                (None, 1)            101         gru_11[0][0]                     \n__________________________________________________________________________________________________\ndense_74 (Dense)                (None, 1)            101         gru_12[0][0]                     \n__________________________________________________________________________________________________\ndense_75 (Dense)                (None, 1)            101         gru_13[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_16 (Concatenate)    (None, 4)            0           dense_72[0][0]                   \n                                                                 dense_73[0][0]                   \n                                                                 dense_74[0][0]                   \n                                                                 dense_75[0][0]                   \n__________________________________________________________________________________________________\ndense_76 (Dense)                (None, 256)          1280        concatenate_16[0][0]             \n__________________________________________________________________________________________________\ndense_77 (Dense)                (None, 1)            257         dense_76[0][0]                   \n==================================================================================================\nTotal params: 5,924,541\nTrainable params: 5,924,541\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 19s 26ms/step - loss: 57.1469 - mae: 57.8345 - val_loss: 47.4785 - val_mae: 48.1613\nEpoch 2/30\n553/553 [==============================] - 13s 24ms/step - loss: 42.2757 - mae: 42.9601 - val_loss: 40.0717 - val_mae: 40.7489\nEpoch 3/30\n553/553 [==============================] - 14s 25ms/step - loss: 37.5011 - mae: 38.1824 - val_loss: 38.2294 - val_mae: 38.9116\nEpoch 4/30\n553/553 [==============================] - 13s 24ms/step - loss: 34.8465 - mae: 35.5268 - val_loss: 37.5299 - val_mae: 38.2126\nEpoch 5/30\n553/553 [==============================] - 13s 24ms/step - loss: 31.5848 - mae: 32.2639 - val_loss: 37.3802 - val_mae: 38.0614\nEpoch 6/30\n553/553 [==============================] - 13s 24ms/step - loss: 29.1901 - mae: 29.8662 - val_loss: 37.6259 - val_mae: 38.3085\nEpoch 7/30\n553/553 [==============================] - 13s 24ms/step - loss: 27.1307 - mae: 27.8061 - val_loss: 37.6979 - val_mae: 38.3806\nEpoch 8/30\n553/553 [==============================] - 13s 24ms/step - loss: 25.4270 - mae: 26.1009 - val_loss: 37.6158 - val_mae: 38.2979\nRestoring model weights from the end of the best epoch.\nEpoch 00008: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict([X_test_summary,X_test_name,X_test_ngbr,X_test_space])\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T16:30:11.181838Z","iopub.execute_input":"2022-09-09T16:30:11.182537Z","iopub.status.idle":"2022-09-09T16:30:17.342421Z","shell.execute_reply.started":"2022-09-09T16:30:11.182502Z","shell.execute_reply":"2022-09-09T16:30:17.341430Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"MSE: 4051.8404530716957\nMAE: 37.79683835862008\n","output_type":"stream"}]},{"cell_type":"markdown","source":"It seems as if the text features don't have nearly as much predictive power as the non-text features. Furthermore, the model already starts overfitting at the third epoch. If this trend carries over to our final model, we should be prepared for using regularization techniques.","metadata":{}},{"cell_type":"markdown","source":"### 4.3.2 LSTM","metadata":{}},{"cell_type":"markdown","source":"We start with a simple LSTM and self-trained embedding to compare performances. After several iterations of LSTM with multiple combinations of text columns, we decide to work with four text features namely - summary,name,neighbourhood_overview and space. The text column ameneties is excluded for the reason that most of this information is present in the summary column. similarly for tthe feature column - transit- some information related to commutation is available in the neighbourhood_overview feature. Thus, the presenece of somewhat redundant information in amenetities and transit columns did not result in any performance improvement on their integration in  the model. As for the house_rules feature, 42% of it's sample consists of empty string, which might be the reason why it's addition to the model worsened the model performance. ","metadata":{}},{"cell_type":"code","source":"def create_w2v_text_model(max_len,NUM_WORDS,wiki_weights):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(max_len,), dtype=tf.int32))\n    model.add(layers.Embedding(input_dim=NUM_WORDS, output_dim=100, input_length=max_len,embeddings_initializer=Constant(wiki_weights),\n                     trainable=False) )\n    model.add(layers.LSTM(rnn_units, return_sequences=False))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\n\ndef create_combined_model(X):\n    X = layers.Flatten()(X)\n    X = layers.Dense(1, activation=\"linear\")(X)\n    print(X.shape)\n    return X\n\n### Initialize Input layers\n    input_summary = tf.keras.Input(shape=(101,), dtype=tf.int32, name=\"summary\")\n    input_name = tf.keras.Input(shape=(8,), dtype=tf.int32, name=\"name\")\n    input_space = tf.keras.Input(shape=(116,), dtype=tf.int32, name=\"space\")\n    input_neighborhood_overview = tf.keras.Input(shape=(109,), dtype=tf.int32, name=\"neighborhood_overview\")\n    \n    ### Create Vectorisation models from text features\n    summary_model = create_w2v_text_model(101,NUM_WORDS_SUMMARY,wiki_weights_summary)\n    name_model = create_w2v_text_model(8,NUM_WORDS_NAME,wiki_weights_name)\n    space_model = create_w2v_text_model(116,NUM_WORDS_SPACE,wiki_weights_space)\n    neighborhood_overview_model = create_w2v_text_model(109,NUM_WORDS_NGBR,wiki_weights_ngbr)\n\n    ### Create Data flow\n    emb_summary = summary_model(input_summary)\n    emb_name = name_model(input_name)\n    emb_space = space_model(input_space)\n    emb_neighborhood_overview = neighborhood_overview_model(input_neighborhood_overview)\n\n    concat_combined = layers.Concatenate(axis=1)([\n                                                    emb_summary,\n                                                    emb_name,\n                                                    emb_space,\n                                                    emb_neighborhood_overview\n                                                    ])\n    print(concat_combined.shape)\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [\n                                    input_summary, \n                                    input_name, \n                                    input_space, \n                                    input_neighborhood_overview\n                                    ], \n                            outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                loss=losses.LogCosh(), metrics=['mae'])\n    return model\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\n\nhistory = model.fit(\n    {\n        \"summary\" : tf.convert_to_tensor(X_tr_summary), \n        \"name\" : tf.convert_to_tensor(X_tr_name),\n        \"space\" : tf.convert_to_tensor(X_tr_space),\n        \"neighborhood_overview\" : tf.convert_to_tensor(X_tr_ngbr)\n    },\n    tf.convert_to_tensor(y_train_nlp.values),\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks = [earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:58:17.895610Z","iopub.execute_input":"2022-09-09T15:58:17.896232Z","iopub.status.idle":"2022-09-09T16:05:22.733002Z","shell.execute_reply.started":"2022-09-09T15:58:17.896193Z","shell.execute_reply":"2022-09-09T16:05:22.732060Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(None, 4)\n(None, 1)\nModel: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nsummary (InputLayer)            [(None, 101)]        0                                            \n__________________________________________________________________________________________________\nname (InputLayer)               [(None, 8)]          0                                            \n__________________________________________________________________________________________________\nspace (InputLayer)              [(None, 116)]        0                                            \n__________________________________________________________________________________________________\nneighborhood_overview (InputLay [(None, 109)]        0                                            \n__________________________________________________________________________________________________\nsequential_32 (Sequential)      (None, 1)            1758377     summary[0][0]                    \n__________________________________________________________________________________________________\nsequential_33 (Sequential)      (None, 1)            658377      name[0][0]                       \n__________________________________________________________________________________________________\nsequential_34 (Sequential)      (None, 1)            1821777     space[0][0]                      \n__________________________________________________________________________________________________\nsequential_35 (Sequential)      (None, 1)            1911177     neighborhood_overview[0][0]      \n__________________________________________________________________________________________________\nconcatenate_12 (Concatenate)    (None, 4)            0           sequential_32[0][0]              \n                                                                 sequential_33[0][0]              \n                                                                 sequential_34[0][0]              \n                                                                 sequential_35[0][0]              \n__________________________________________________________________________________________________\nflatten_7 (Flatten)             (None, 4)            0           concatenate_12[0][0]             \n__________________________________________________________________________________________________\ndense_55 (Dense)                (None, 1)            5           flatten_7[0][0]                  \n==================================================================================================\nTotal params: 6,149,713\nTrainable params: 469,513\nNon-trainable params: 5,680,200\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 19s 27ms/step - loss: 83.5090 - mae: 84.1973 - val_loss: 73.2944 - val_mae: 73.9826\nEpoch 2/30\n553/553 [==============================] - 14s 25ms/step - loss: 69.0943 - mae: 69.7798 - val_loss: 64.6892 - val_mae: 65.3724\nEpoch 3/30\n553/553 [==============================] - 14s 25ms/step - loss: 62.4586 - mae: 63.1440 - val_loss: 60.0009 - val_mae: 60.6876\nEpoch 4/30\n553/553 [==============================] - 14s 25ms/step - loss: 58.8279 - mae: 59.5158 - val_loss: 57.5545 - val_mae: 58.2392\nEpoch 5/30\n553/553 [==============================] - 14s 25ms/step - loss: 56.9754 - mae: 57.6636 - val_loss: 56.4842 - val_mae: 57.1756\nEpoch 6/30\n553/553 [==============================] - 14s 25ms/step - loss: 56.2347 - mae: 56.9233 - val_loss: 56.1388 - val_mae: 56.8291\nEpoch 7/30\n553/553 [==============================] - 14s 25ms/step - loss: 56.0253 - mae: 56.7072 - val_loss: 56.0840 - val_mae: 56.7595\nEpoch 8/30\n553/553 [==============================] - 14s 25ms/step - loss: 55.9544 - mae: 56.6369 - val_loss: 55.7052 - val_mae: 56.3925\nEpoch 9/30\n553/553 [==============================] - 14s 25ms/step - loss: 55.0510 - mae: 55.7385 - val_loss: 53.6264 - val_mae: 54.3158\nEpoch 10/30\n553/553 [==============================] - 14s 25ms/step - loss: 53.6502 - mae: 54.3376 - val_loss: 52.2954 - val_mae: 52.9841\nEpoch 11/30\n553/553 [==============================] - 14s 26ms/step - loss: 50.6656 - mae: 51.3507 - val_loss: 49.7538 - val_mae: 50.4405\nEpoch 12/30\n553/553 [==============================] - 14s 25ms/step - loss: 49.3542 - mae: 50.0399 - val_loss: 49.3550 - val_mae: 50.0386\nEpoch 13/30\n553/553 [==============================] - 14s 25ms/step - loss: 48.1661 - mae: 48.8515 - val_loss: 47.6030 - val_mae: 48.2886\nEpoch 14/30\n553/553 [==============================] - 14s 25ms/step - loss: 45.7994 - mae: 46.4835 - val_loss: 46.1984 - val_mae: 46.8817\nEpoch 15/30\n553/553 [==============================] - 14s 25ms/step - loss: 44.3190 - mae: 45.0024 - val_loss: 44.8101 - val_mae: 45.4946\nEpoch 16/30\n553/553 [==============================] - 14s 25ms/step - loss: 43.7028 - mae: 44.3860 - val_loss: 43.9389 - val_mae: 44.6233\nEpoch 17/30\n553/553 [==============================] - 14s 25ms/step - loss: 43.1664 - mae: 43.8492 - val_loss: 43.2949 - val_mae: 43.9775\nEpoch 18/30\n553/553 [==============================] - 14s 25ms/step - loss: 42.7473 - mae: 43.4301 - val_loss: 43.0706 - val_mae: 43.7544\nEpoch 19/30\n553/553 [==============================] - 14s 25ms/step - loss: 42.3528 - mae: 43.0349 - val_loss: 42.6957 - val_mae: 43.3780\nEpoch 20/30\n553/553 [==============================] - 14s 26ms/step - loss: 41.9720 - mae: 42.6543 - val_loss: 42.4055 - val_mae: 43.0893\nEpoch 21/30\n553/553 [==============================] - 14s 25ms/step - loss: 41.7051 - mae: 42.3880 - val_loss: 41.9337 - val_mae: 42.6165\nEpoch 22/30\n553/553 [==============================] - 14s 26ms/step - loss: 41.3867 - mae: 42.0691 - val_loss: 41.8392 - val_mae: 42.5209\nEpoch 23/30\n553/553 [==============================] - 14s 25ms/step - loss: 41.0282 - mae: 41.7101 - val_loss: 41.4601 - val_mae: 42.1428\nEpoch 24/30\n553/553 [==============================] - 14s 25ms/step - loss: 40.8569 - mae: 41.5390 - val_loss: 41.6305 - val_mae: 42.3137\nEpoch 25/30\n553/553 [==============================] - 14s 25ms/step - loss: 40.6835 - mae: 41.3658 - val_loss: 41.2614 - val_mae: 41.9438\nEpoch 26/30\n553/553 [==============================] - 14s 25ms/step - loss: 40.4251 - mae: 41.1070 - val_loss: 40.9837 - val_mae: 41.6670\nEpoch 27/30\n553/553 [==============================] - 14s 25ms/step - loss: 40.1713 - mae: 40.8534 - val_loss: 40.9977 - val_mae: 41.6807\nEpoch 28/30\n553/553 [==============================] - 14s 25ms/step - loss: 39.9956 - mae: 40.6767 - val_loss: 40.5948 - val_mae: 41.2779\nEpoch 29/30\n553/553 [==============================] - 14s 25ms/step - loss: 39.8469 - mae: 40.5284 - val_loss: 40.4011 - val_mae: 41.0842\nEpoch 30/30\n553/553 [==============================] - 14s 25ms/step - loss: 39.7640 - mae: 40.4455 - val_loss: 41.3392 - val_mae: 42.0228\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict([X_test_summary,X_test_name,X_test_space,X_test_ngbr])\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T16:11:30.710225Z","iopub.execute_input":"2022-09-09T16:11:30.710617Z","iopub.status.idle":"2022-09-09T16:11:34.679995Z","shell.execute_reply.started":"2022-09-09T16:11:30.710583Z","shell.execute_reply":"2022-09-09T16:11:34.678481Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"MSE: 5002.26633233977\nMAE: 40.84218794995281\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Suprisingly, Using LSTMs instead of GRUs and fine-tuneable pre-trained embeddings is unable to produce above-benchmark performance. Although it is observable that this model starts to overfit much later than the GRU model, even though we did not use any regularization. However, from the results so far, it is apparent that the text features either do not hold much predictive power, or they cannot be harnessed well by our modeling approach.","metadata":{}},{"cell_type":"markdown","source":"### 4.3.3 CNN-LSTM","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rnn_units = 128\ndef create_w2v_text_model(max_len,NUM_WORDS,wiki_weights):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(max_len,), dtype=tf.int32))\n    model.add(layers.Embedding(input_dim=NUM_WORDS, output_dim=100, input_length=max_len,embeddings_initializer=Constant(wiki_weights),\n                     trainable=False) )\n    model.add(layers.Conv1D(filters=16,kernel_size=5))\n    model.add(layers.AveragePooling1D(pool_size=2,strides=2))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.LSTM(rnn_units, return_sequences=True, kernel_regularizer='l2'))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\n\ndef create_combined_model(X):\n    X = layers.Flatten()(X)\n    X = layers.Dropout(0.2)(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    #X = layers.Dense(64, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"relu\")(X)\n    print(X.shape)\n    return X\n\ndef create_model():\n    \n    ### Initialize Input layers\n    input_summary = tf.keras.Input(shape=(101,), dtype=tf.int32, name=\"summary\")\n    input_name = tf.keras.Input(shape=(8,), dtype=tf.int32, name=\"name\")\n    input_space = tf.keras.Input(shape=(116,), dtype=tf.int32, name=\"space\")\n    input_neighborhood_overview = tf.keras.Input(shape=(109,), dtype=tf.int32, name=\"neighborhood_overview\")\n    \n    ### Create Vectorisation models from text features\n    summary_model = create_w2v_text_model(101,NUM_WORDS_SUMMARY,wiki_weights_summary)\n    name_model = create_w2v_text_model(8,NUM_WORDS_NAME,wiki_weights_name)\n    space_model = create_w2v_text_model(116,NUM_WORDS_SPACE,wiki_weights_space)\n    neighborhood_overview_model = create_w2v_text_model(109,NUM_WORDS_NGBR,wiki_weights_ngbr)\n\n    ### Create Data flow\n    emb_summary = summary_model(input_summary)\n    emb_name = name_model(input_name)\n    emb_space = space_model(input_space)\n    emb_neighborhood_overview = neighborhood_overview_model(input_neighborhood_overview)\n\n    concat_combined = layers.Concatenate(axis=1)([\n                                                    emb_summary,\n                                                    emb_name,\n                                                    emb_space,\n                                                    emb_neighborhood_overview\n                                                    ])\n    print(concat_combined.shape)\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [\n                                    input_summary, \n                                    input_name, \n                                    input_space, \n                                    input_neighborhood_overview\n                                    ], \n                            outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                loss=losses.LogCosh(), metrics=['mae'])\n    return model\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\n\nhistory = model.fit(\n    {\n        \"summary\" : tf.convert_to_tensor(X_tr_summary), \n        \"name\" : tf.convert_to_tensor(X_tr_name),\n        \"space\" : tf.convert_to_tensor(X_tr_space),\n        \"neighborhood_overview\" : tf.convert_to_tensor(X_tr_ngbr)\n    },\n    tf.convert_to_tensor(y_train_nlp.values),\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks = [earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:49:30.483455Z","iopub.execute_input":"2022-09-09T15:49:30.484074Z","iopub.status.idle":"2022-09-09T15:52:21.220380Z","shell.execute_reply.started":"2022-09-09T15:49:30.484029Z","shell.execute_reply":"2022-09-09T15:52:21.219387Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"(None, 158, 1)\n(None, 1)\nModel: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nsummary (InputLayer)            [(None, 101)]        0                                            \n__________________________________________________________________________________________________\nname (InputLayer)               [(None, 8)]          0                                            \n__________________________________________________________________________________________________\nspace (InputLayer)              [(None, 116)]        0                                            \n__________________________________________________________________________________________________\nneighborhood_overview (InputLay [(None, 109)]        0                                            \n__________________________________________________________________________________________________\nsequential_28 (Sequential)      (None, 48, 1)        1723385     summary[0][0]                    \n__________________________________________________________________________________________________\nsequential_29 (Sequential)      (None, 2, 1)         623385      name[0][0]                       \n__________________________________________________________________________________________________\nsequential_30 (Sequential)      (None, 56, 1)        1786785     space[0][0]                      \n__________________________________________________________________________________________________\nsequential_31 (Sequential)      (None, 52, 1)        1876185     neighborhood_overview[0][0]      \n__________________________________________________________________________________________________\nconcatenate_11 (Concatenate)    (None, 158, 1)       0           sequential_28[0][0]              \n                                                                 sequential_29[0][0]              \n                                                                 sequential_30[0][0]              \n                                                                 sequential_31[0][0]              \n__________________________________________________________________________________________________\nflatten_6 (Flatten)             (None, 158)          0           concatenate_11[0][0]             \n__________________________________________________________________________________________________\ndropout_38 (Dropout)            (None, 158)          0           flatten_6[0][0]                  \n__________________________________________________________________________________________________\ndense_49 (Dense)                (None, 128)          20352       dropout_38[0][0]                 \n__________________________________________________________________________________________________\ndense_50 (Dense)                (None, 1)            129         dense_49[0][0]                   \n==================================================================================================\nTotal params: 6,030,221\nTrainable params: 350,021\nNon-trainable params: 5,680,200\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 16s 20ms/step - loss: 61.0967 - mae: 60.9025 - val_loss: 53.1177 - val_mae: 53.1091\nEpoch 2/30\n553/553 [==============================] - 10s 19ms/step - loss: 50.6680 - mae: 50.6794 - val_loss: 47.8999 - val_mae: 47.9368\nEpoch 3/30\n553/553 [==============================] - 10s 18ms/step - loss: 47.4683 - mae: 47.5471 - val_loss: 44.9890 - val_mae: 45.1067\nEpoch 4/30\n553/553 [==============================] - 10s 18ms/step - loss: 45.5776 - mae: 45.7226 - val_loss: 43.9565 - val_mae: 44.1257\nEpoch 5/30\n553/553 [==============================] - 11s 19ms/step - loss: 44.7052 - mae: 44.8991 - val_loss: 43.4248 - val_mae: 43.6357\nEpoch 6/30\n553/553 [==============================] - 10s 18ms/step - loss: 44.3400 - mae: 44.5711 - val_loss: 43.0692 - val_mae: 43.3124\nEpoch 7/30\n553/553 [==============================] - 10s 18ms/step - loss: 43.8030 - mae: 44.0621 - val_loss: 42.8966 - val_mae: 43.1692\nEpoch 8/30\n553/553 [==============================] - 10s 19ms/step - loss: 43.4082 - mae: 43.6917 - val_loss: 42.5471 - val_mae: 42.8393\nEpoch 9/30\n553/553 [==============================] - 10s 18ms/step - loss: 43.1452 - mae: 43.4474 - val_loss: 42.5572 - val_mae: 42.8697\nEpoch 10/30\n553/553 [==============================] - 10s 18ms/step - loss: 42.9131 - mae: 43.2316 - val_loss: 42.6174 - val_mae: 42.9437\nEpoch 11/30\n553/553 [==============================] - 10s 19ms/step - loss: 42.7466 - mae: 43.0807 - val_loss: 42.1015 - val_mae: 42.4429\nEpoch 12/30\n553/553 [==============================] - 10s 18ms/step - loss: 42.5192 - mae: 42.8673 - val_loss: 41.8389 - val_mae: 42.1924\nEpoch 13/30\n553/553 [==============================] - 10s 18ms/step - loss: 42.2865 - mae: 42.6462 - val_loss: 41.5493 - val_mae: 41.9129\nEpoch 14/30\n553/553 [==============================] - 11s 19ms/step - loss: 42.3268 - mae: 42.6961 - val_loss: 41.6740 - val_mae: 42.0479\nEpoch 15/30\n553/553 [==============================] - 10s 18ms/step - loss: 42.0570 - mae: 42.4341 - val_loss: 41.7498 - val_mae: 42.1311\nEpoch 16/30\n553/553 [==============================] - 10s 19ms/step - loss: 42.0793 - mae: 42.4638 - val_loss: 41.5408 - val_mae: 41.9276\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict([X_test_summary,X_test_name,X_test_space,X_test_ngbr])\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:53:07.814305Z","iopub.execute_input":"2022-09-09T15:53:07.815288Z","iopub.status.idle":"2022-09-09T15:54:03.108591Z","shell.execute_reply.started":"2022-09-09T15:53:07.815252Z","shell.execute_reply":"2022-09-09T15:54:03.107479Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"MSE: 4639.6485301801995\nMAE: 40.91600014799659\n","output_type":"stream"}]},{"cell_type":"markdown","source":"CNN-LSTMs with pre-trained embeddings performs comparable to LSTMs and worse than GRUs in terms of MAE. But it doesn't overfit the split even once in 16 epochs. This shows the robustness of the CNN-LSTM in our case.","metadata":{}},{"cell_type":"markdown","source":"### 4.3.4 Bidirectional LSTM","metadata":{}},{"cell_type":"markdown","source":"Since we are dealing with predefined sequences, we can consider using a bidirectional LSTM architecture to get a more accurate prediction.","metadata":{}},{"cell_type":"code","source":"rnn_units = 128\n\ndef create_w2v_text_model(max_len,NUM_WORDS,wiki_weights):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(max_len,), dtype=tf.int32))\n    model.add(layers.Embedding(input_dim=NUM_WORDS, output_dim=100, input_length=max_len,embeddings_initializer=Constant(wiki_weights),\n                     trainable=False) )\n    model.add(layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True, kernel_regularizer='l2')))\n    # model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\n\ndef create_combined_model(X):\n    X = layers.Flatten()(X)\n    X = layers.Dropout(0.1)(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    X = layers.Dense(64, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"linear\")(X)\n    print(X.shape)\n    return X\n\ndef create_model():\n    \n    ### Initialize Input layers\n    input_summary = tf.keras.Input(shape=(101,), dtype=tf.int32, name=\"summary\")\n    input_name = tf.keras.Input(shape=(8,), dtype=tf.int32, name=\"name\")\n    input_space = tf.keras.Input(shape=(116,), dtype=tf.int32, name=\"space\")\n    input_neighborhood_overview = tf.keras.Input(shape=(109,), dtype=tf.int32, name=\"neighborhood_overview\")\n    \n    ### Create Vectorisation models from text features\n    summary_model = create_w2v_text_model(101,NUM_WORDS_SUMMARY,wiki_weights_summary)\n    name_model = create_w2v_text_model(8,NUM_WORDS_NAME,wiki_weights_name)\n    space_model = create_w2v_text_model(116,NUM_WORDS_SPACE,wiki_weights_space)\n    neighborhood_overview_model = create_w2v_text_model(109,NUM_WORDS_NGBR,wiki_weights_ngbr)\n\n    ### Create Data flow\n    emb_summary = summary_model(input_summary)\n    emb_name = name_model(input_name)\n    emb_space = space_model(input_space)\n    emb_neighborhood_overview = neighborhood_overview_model(input_neighborhood_overview)\n\n    concat_combined = layers.Concatenate(axis=1)([\n                                                    emb_summary,\n                                                    emb_name,\n                                                    emb_space,\n                                                    emb_neighborhood_overview\n                                                    ])\n    print(concat_combined.shape)\n    output = create_combined_model(concat_combined)\n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [\n                                    input_summary, \n                                    input_name, \n                                    input_space, \n                                    input_neighborhood_overview\n                                    ], \n                            outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                loss=losses.LogCosh(), metrics=['mae'])\n    return model\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\n\nhistory = model.fit(\n    {\n        \"summary\" : tf.convert_to_tensor(X_tr_summary), \n        \"name\" : tf.convert_to_tensor(X_tr_name),\n        \"space\" : tf.convert_to_tensor(X_tr_space),\n        \"neighborhood_overview\" : tf.convert_to_tensor(X_tr_ngbr)\n    },\n    tf.convert_to_tensor(y_train_nlp.values),\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks = [earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T16:33:01.750463Z","iopub.execute_input":"2022-09-09T16:33:01.750944Z","iopub.status.idle":"2022-09-09T16:45:14.592414Z","shell.execute_reply.started":"2022-09-09T16:33:01.750902Z","shell.execute_reply":"2022-09-09T16:45:14.591465Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"(None, 334, 1)\n(None, 1)\nModel: \"model_12\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nsummary (InputLayer)            [(None, 101)]        0                                            \n__________________________________________________________________________________________________\nname (InputLayer)               [(None, 8)]          0                                            \n__________________________________________________________________________________________________\nspace (InputLayer)              [(None, 116)]        0                                            \n__________________________________________________________________________________________________\nneighborhood_overview (InputLay [(None, 109)]        0                                            \n__________________________________________________________________________________________________\nsequential_36 (Sequential)      (None, 101, 1)       1875753     summary[0][0]                    \n__________________________________________________________________________________________________\nsequential_37 (Sequential)      (None, 8, 1)         775753      name[0][0]                       \n__________________________________________________________________________________________________\nsequential_38 (Sequential)      (None, 116, 1)       1939153     space[0][0]                      \n__________________________________________________________________________________________________\nsequential_39 (Sequential)      (None, 109, 1)       2028553     neighborhood_overview[0][0]      \n__________________________________________________________________________________________________\nconcatenate_17 (Concatenate)    (None, 334, 1)       0           sequential_36[0][0]              \n                                                                 sequential_37[0][0]              \n                                                                 sequential_38[0][0]              \n                                                                 sequential_39[0][0]              \n__________________________________________________________________________________________________\nflatten_8 (Flatten)             (None, 334)          0           concatenate_17[0][0]             \n__________________________________________________________________________________________________\ndropout_39 (Dropout)            (None, 334)          0           flatten_8[0][0]                  \n__________________________________________________________________________________________________\ndense_82 (Dense)                (None, 128)          42880       dropout_39[0][0]                 \n__________________________________________________________________________________________________\ndense_83 (Dense)                (None, 64)           8256        dense_82[0][0]                   \n__________________________________________________________________________________________________\ndense_84 (Dense)                (None, 1)            65          dense_83[0][0]                   \n==================================================================================================\nTotal params: 6,670,413\nTrainable params: 990,213\nNon-trainable params: 5,680,200\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 42s 57ms/step - loss: 63.2016 - mae: 56.0600 - val_loss: 49.6085 - val_mae: 45.7350\nEpoch 2/30\n553/553 [==============================] - 29s 52ms/step - loss: 47.0851 - mae: 44.3443 - val_loss: 45.7118 - val_mae: 43.6949\nEpoch 3/30\n553/553 [==============================] - 28s 51ms/step - loss: 44.3210 - mae: 42.6051 - val_loss: 43.8322 - val_mae: 42.3152\nEpoch 4/30\n553/553 [==============================] - 29s 52ms/step - loss: 43.1217 - mae: 41.7102 - val_loss: 42.8616 - val_mae: 41.5384\nEpoch 5/30\n553/553 [==============================] - 28s 52ms/step - loss: 42.5627 - mae: 41.2993 - val_loss: 42.1534 - val_mae: 40.9463\nEpoch 6/30\n553/553 [==============================] - 29s 52ms/step - loss: 41.8386 - mae: 40.6753 - val_loss: 41.7601 - val_mae: 40.6390\nEpoch 7/30\n553/553 [==============================] - 29s 52ms/step - loss: 41.4334 - mae: 40.3481 - val_loss: 41.4233 - val_mae: 40.3696\nEpoch 8/30\n553/553 [==============================] - 29s 52ms/step - loss: 41.1528 - mae: 40.1211 - val_loss: 41.7631 - val_mae: 40.7514\nEpoch 9/30\n553/553 [==============================] - 29s 52ms/step - loss: 40.8728 - mae: 39.8821 - val_loss: 41.1092 - val_mae: 40.1406\nEpoch 10/30\n553/553 [==============================] - 29s 52ms/step - loss: 40.4788 - mae: 39.5282 - val_loss: 40.6369 - val_mae: 39.7051\nEpoch 11/30\n553/553 [==============================] - 28s 52ms/step - loss: 40.2273 - mae: 39.3103 - val_loss: 40.6118 - val_mae: 39.7133\nEpoch 12/30\n553/553 [==============================] - 29s 52ms/step - loss: 39.9958 - mae: 39.1112 - val_loss: 40.2306 - val_mae: 39.3621\nEpoch 13/30\n553/553 [==============================] - 28s 51ms/step - loss: 39.7616 - mae: 38.9048 - val_loss: 40.1181 - val_mae: 39.2764\nEpoch 14/30\n553/553 [==============================] - 28s 51ms/step - loss: 39.6167 - mae: 38.7856 - val_loss: 40.0454 - val_mae: 39.2284\nEpoch 15/30\n553/553 [==============================] - 28s 51ms/step - loss: 39.4317 - mae: 38.6235 - val_loss: 40.0661 - val_mae: 39.2692\nEpoch 16/30\n553/553 [==============================] - 29s 52ms/step - loss: 39.2026 - mae: 38.4119 - val_loss: 40.1395 - val_mae: 39.3574\nEpoch 17/30\n553/553 [==============================] - 29s 52ms/step - loss: 39.1740 - mae: 38.3988 - val_loss: 39.7268 - val_mae: 38.9604\nEpoch 18/30\n553/553 [==============================] - 29s 52ms/step - loss: 38.8730 - mae: 38.1129 - val_loss: 40.1190 - val_mae: 39.3675\nEpoch 19/30\n553/553 [==============================] - 29s 52ms/step - loss: 38.7841 - mae: 38.0389 - val_loss: 39.5113 - val_mae: 38.7748\nEpoch 20/30\n553/553 [==============================] - 29s 52ms/step - loss: 38.5905 - mae: 37.8584 - val_loss: 39.3388 - val_mae: 38.6128\nEpoch 21/30\n553/553 [==============================] - 29s 52ms/step - loss: 38.5810 - mae: 37.8603 - val_loss: 39.2380 - val_mae: 38.5236\nEpoch 22/30\n553/553 [==============================] - 29s 52ms/step - loss: 38.3769 - mae: 37.6680 - val_loss: 39.0006 - val_mae: 38.2990\nEpoch 23/30\n553/553 [==============================] - 28s 51ms/step - loss: 38.1050 - mae: 37.4047 - val_loss: 39.1135 - val_mae: 38.4197\nEpoch 24/30\n553/553 [==============================] - 29s 52ms/step - loss: 37.9737 - mae: 37.2827 - val_loss: 39.3509 - val_mae: 38.6650\nEpoch 25/30\n553/553 [==============================] - 28s 52ms/step - loss: 37.8453 - mae: 37.1620 - val_loss: 39.1977 - val_mae: 38.5190\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict([X_test_summary,X_test_name,X_test_space,X_test_ngbr])\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T16:48:06.342184Z","iopub.execute_input":"2022-09-09T16:48:06.342644Z","iopub.status.idle":"2022-09-09T16:48:43.953101Z","shell.execute_reply.started":"2022-09-09T16:48:06.342610Z","shell.execute_reply":"2022-09-09T16:48:43.952161Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"MSE: 4064.1696017568393\nMAE: 37.443344058250446\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As expected, bidirectional LSTM performs better than the unidirectional ones. Although, the performance MAE-wise is best among RNNs architecture, yet it takes considerably long to train and also overfits the training data. which is why we chose to work CNN- LSTMs since its performance is relatively ok and it doesn't overfit our train data.","metadata":{}},{"cell_type":"markdown","source":"## 4.4 Full Model Architecture\n\nWe now need to make a decision on how to bring text and non-text predictions together. \n\nOur architecture follows the following order:\n1. Train LSTMs on text and have them put out a single ReLU value. \n2. Concatenate these values with the non-text data\n3. Train a deep neural network on the concatenated features\n\nThe architecture of the dense layers after the concatenation follows a bottleneck fashion, which is an often-used heuristic for building neural networks. The amounts of neurons in each layer was somewhat determined in a trial-and-error fashion where we noticed that a high amount of neurons boosted performance considerably.","metadata":{}},{"cell_type":"code","source":"train_num_cols = X_train_nlp.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\nval_num_cols = X_test_nlp.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])\ntest_num_cols = test.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:30:21.903449Z","iopub.execute_input":"2022-09-09T17:30:21.904043Z","iopub.status.idle":"2022-09-09T17:30:21.928262Z","shell.execute_reply.started":"2022-09-09T17:30:21.903998Z","shell.execute_reply":"2022-09-09T17:30:21.927259Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers, losses\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:20:41.479854Z","iopub.execute_input":"2022-09-09T15:20:41.480837Z","iopub.status.idle":"2022-09-09T15:20:41.486028Z","shell.execute_reply.started":"2022-09-09T15:20:41.480770Z","shell.execute_reply":"2022-09-09T15:20:41.485051Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_ann():\n    model = models.Sequential()\n    model.add(layers.Dense(16, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(8, activation='relu'))\n    # model.add(layers.Dense(1, activation='linear'))\n    # model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])\n    return model\n\n\nrnn_units = 128\n\ndef create_w2v_text_model(max_len,NUM_WORDS,wiki_weights):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(max_len,), dtype=tf.int32))\n    model.add(layers.Embedding(input_dim=NUM_WORDS, output_dim=100, input_length=max_len,embeddings_initializer=Constant(wiki_weights),\n                     trainable=False) )\n    model.add(layers.Conv1D(filters=16,kernel_size=5))\n    model.add(layers.AveragePooling1D(pool_size=2,strides=2))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.LSTM(rnn_units, return_sequences=True, kernel_regularizer='l2'))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\n\ndef create_combined_model(X):\n    X = layers.Dropout(0.2)(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    # X = layers.Dense(64, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"relu\")(X)\n    print(X.shape)\n    return X\n\n\ndef create_model():\n    \n   ### Initialize Input layers\n    input_summary = tf.keras.Input(shape=(101,), dtype=tf.int32, name=\"summary\")\n    input_name = tf.keras.Input(shape=(8,), dtype=tf.int32, name=\"name\")\n    input_space = tf.keras.Input(shape=(116,), dtype=tf.int32, name=\"space\")\n    input_neighborhood_overview = tf.keras.Input(shape=(109,), dtype=tf.int32, name=\"neighborhood_overview\")\n    input_numeric = tf.keras.Input(shape=(train_num_cols.shape[1],), dtype=tf.float64, name=\"numeric\")\n    \n    ### Create Vectorisation models from text features\n    summary_model = create_w2v_text_model(101,NUM_WORDS_SUMMARY,wiki_weights_summary)\n    name_model = create_w2v_text_model(8,NUM_WORDS_NAME,wiki_weights_name)\n    space_model = create_w2v_text_model(116,NUM_WORDS_SPACE,wiki_weights_space)\n    neighborhood_overview_model = create_w2v_text_model(109,NUM_WORDS_NGBR,wiki_weights_ngbr)\n\n    ### Create Data flow\n    emb_summary = summary_model(input_summary)\n    emb_name = name_model(input_name)\n    emb_space = space_model(input_space)\n    emb_neighborhood_overview = neighborhood_overview_model(input_neighborhood_overview)\n    numeric_layers = create_ann()(input_numeric)\n\n    concat_combined = layers.Concatenate(axis=1)([\n                                                    emb_summary,\n                                                    emb_name,\n                                                    emb_space,\n                                                    emb_neighborhood_overview\n                                                    ])\n    print(concat_combined.shape)\n    concat_combined = layers.Flatten()(concat_combined)\n    concat_combined = layers.Concatenate()([concat_combined, numeric_layers])\n    output = create_combined_model(concat_combined)\n    \n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [\n                                    input_summary, \n                                    input_name, \n                                    input_space, \n                                    input_neighborhood_overview,\n                                    input_numeric\n                                    ], \n                            outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                loss=losses.LogCosh(), metrics=['mae'])\n    return model\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    {\n        \"summary\" : tf.convert_to_tensor(X_tr_summary), \n        \"name\" : tf.convert_to_tensor(X_tr_name),\n        \"space\" : tf.convert_to_tensor(X_tr_space),\n        \"neighborhood_overview\" : tf.convert_to_tensor(X_tr_ngbr),\n        \"numeric\" : tf.convert_to_tensor(train_num_cols)\n    },\n    tf.convert_to_tensor(y_train_nlp.values),\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks = [earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:39:45.928051Z","iopub.execute_input":"2022-09-09T15:39:45.928595Z","iopub.status.idle":"2022-09-09T15:45:15.792150Z","shell.execute_reply.started":"2022-09-09T15:39:45.928558Z","shell.execute_reply":"2022-09-09T15:45:15.791080Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(None, 158, 1)\n(None, 1)\nModel: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nsummary (InputLayer)            [(None, 101)]        0                                            \n__________________________________________________________________________________________________\nname (InputLayer)               [(None, 8)]          0                                            \n__________________________________________________________________________________________________\nspace (InputLayer)              [(None, 116)]        0                                            \n__________________________________________________________________________________________________\nneighborhood_overview (InputLay [(None, 109)]        0                                            \n__________________________________________________________________________________________________\nsequential_19 (Sequential)      (None, 48, 1)        1723385     summary[0][0]                    \n__________________________________________________________________________________________________\nsequential_20 (Sequential)      (None, 2, 1)         623385      name[0][0]                       \n__________________________________________________________________________________________________\nsequential_21 (Sequential)      (None, 56, 1)        1786785     space[0][0]                      \n__________________________________________________________________________________________________\nsequential_22 (Sequential)      (None, 52, 1)        1876185     neighborhood_overview[0][0]      \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 158, 1)       0           sequential_19[0][0]              \n                                                                 sequential_20[0][0]              \n                                                                 sequential_21[0][0]              \n                                                                 sequential_22[0][0]              \n__________________________________________________________________________________________________\nnumeric (InputLayer)            [(None, 33)]         0                                            \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 158)          0           concatenate_8[0][0]              \n__________________________________________________________________________________________________\nsequential_23 (Sequential)      (None, 8)            680         numeric[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 166)          0           flatten_4[0][0]                  \n                                                                 sequential_23[0][0]              \n__________________________________________________________________________________________________\ndropout_28 (Dropout)            (None, 166)          0           concatenate_9[0][0]              \n__________________________________________________________________________________________________\ndense_37 (Dense)                (None, 128)          21376       dropout_28[0][0]                 \n__________________________________________________________________________________________________\ndense_38 (Dense)                (None, 1)            129         dense_37[0][0]                   \n==================================================================================================\nTotal params: 6,031,925\nTrainable params: 351,725\nNon-trainable params: 5,680,200\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n553/553 [==============================] - 18s 22ms/step - loss: 62.1223 - mae: 62.0104 - val_loss: 53.1743 - val_mae: 53.3080\nEpoch 2/30\n553/553 [==============================] - 10s 18ms/step - loss: 49.4666 - mae: 49.6149 - val_loss: 44.3964 - val_mae: 44.5639\nEpoch 3/30\n553/553 [==============================] - 10s 19ms/step - loss: 42.4607 - mae: 42.6784 - val_loss: 38.1466 - val_mae: 38.4091\nEpoch 4/30\n553/553 [==============================] - 11s 20ms/step - loss: 38.9929 - mae: 39.2892 - val_loss: 35.6315 - val_mae: 35.9571\nEpoch 5/30\n553/553 [==============================] - 10s 18ms/step - loss: 37.6767 - mae: 38.0252 - val_loss: 34.8984 - val_mae: 35.2693\nEpoch 6/30\n553/553 [==============================] - 10s 18ms/step - loss: 36.9504 - mae: 37.3393 - val_loss: 33.8079 - val_mae: 34.2110\nEpoch 7/30\n553/553 [==============================] - 11s 19ms/step - loss: 36.3433 - mae: 36.7612 - val_loss: 33.3716 - val_mae: 33.8004\nEpoch 8/30\n553/553 [==============================] - 10s 18ms/step - loss: 36.0753 - mae: 36.5166 - val_loss: 33.0065 - val_mae: 33.4565\nEpoch 9/30\n553/553 [==============================] - 10s 18ms/step - loss: 35.6402 - mae: 36.1013 - val_loss: 32.7830 - val_mae: 33.2516\nEpoch 10/30\n553/553 [==============================] - 11s 19ms/step - loss: 35.3710 - mae: 35.8475 - val_loss: 32.5017 - val_mae: 32.9844\nEpoch 11/30\n553/553 [==============================] - 10s 18ms/step - loss: 35.3316 - mae: 35.8214 - val_loss: 32.4887 - val_mae: 32.9826\nEpoch 12/30\n553/553 [==============================] - 10s 19ms/step - loss: 35.1222 - mae: 35.6248 - val_loss: 32.1403 - val_mae: 32.6474\nEpoch 13/30\n553/553 [==============================] - 11s 19ms/step - loss: 34.9235 - mae: 35.4369 - val_loss: 32.1221 - val_mae: 32.6406\nEpoch 14/30\n553/553 [==============================] - 10s 18ms/step - loss: 34.5575 - mae: 35.0799 - val_loss: 31.7936 - val_mae: 32.3159\nEpoch 15/30\n553/553 [==============================] - 10s 18ms/step - loss: 34.4849 - mae: 35.0120 - val_loss: 31.5802 - val_mae: 32.1082\nEpoch 16/30\n553/553 [==============================] - 11s 19ms/step - loss: 34.3290 - mae: 34.8614 - val_loss: 31.5294 - val_mae: 32.0632\nEpoch 17/30\n553/553 [==============================] - 10s 18ms/step - loss: 34.2155 - mae: 34.7531 - val_loss: 31.3545 - val_mae: 31.8940\nEpoch 18/30\n553/553 [==============================] - 10s 18ms/step - loss: 34.1091 - mae: 34.6530 - val_loss: 31.3454 - val_mae: 31.8899\nEpoch 19/30\n553/553 [==============================] - 11s 19ms/step - loss: 33.8339 - mae: 34.3840 - val_loss: 31.3474 - val_mae: 31.9003\nEpoch 20/30\n553/553 [==============================] - 10s 19ms/step - loss: 33.9002 - mae: 34.4551 - val_loss: 31.2540 - val_mae: 31.8089\nEpoch 21/30\n553/553 [==============================] - 10s 18ms/step - loss: 33.7882 - mae: 34.3466 - val_loss: 31.0889 - val_mae: 31.6486\nEpoch 22/30\n553/553 [==============================] - 11s 19ms/step - loss: 33.6188 - mae: 34.1803 - val_loss: 31.2903 - val_mae: 31.8535\nEpoch 23/30\n553/553 [==============================] - 10s 18ms/step - loss: 33.6500 - mae: 34.2157 - val_loss: 31.1018 - val_mae: 31.6663\nEpoch 24/30\n553/553 [==============================] - 10s 18ms/step - loss: 33.4572 - mae: 34.0241 - val_loss: 31.0110 - val_mae: 31.5767\nEpoch 25/30\n553/553 [==============================] - 11s 20ms/step - loss: 33.2251 - mae: 33.7946 - val_loss: 30.7632 - val_mae: 31.3324\nEpoch 26/30\n553/553 [==============================] - 10s 19ms/step - loss: 33.2567 - mae: 33.8283 - val_loss: 30.9573 - val_mae: 31.5300\nEpoch 27/30\n553/553 [==============================] - 10s 19ms/step - loss: 33.1124 - mae: 33.6874 - val_loss: 30.7046 - val_mae: 31.2795\nEpoch 28/30\n553/553 [==============================] - 11s 20ms/step - loss: 33.2141 - mae: 33.7910 - val_loss: 30.7029 - val_mae: 31.2799\nEpoch 29/30\n553/553 [==============================] - 10s 19ms/step - loss: 33.0397 - mae: 33.6189 - val_loss: 30.7747 - val_mae: 31.3528\nEpoch 30/30\n553/553 [==============================] - 11s 19ms/step - loss: 32.9519 - mae: 33.5322 - val_loss: 30.5279 - val_mae: 31.1076\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict([X_test_summary,X_test_name,X_test_space,X_test_ngbr,val_num_cols])\nprint(f\"MSE: {mean_squared_error(y_test_nlp, prediction)}\")\nprint(f\"MAE: {mean_absolute_error(y_test_nlp, prediction)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:45:23.830942Z","iopub.execute_input":"2022-09-09T15:45:23.831606Z","iopub.status.idle":"2022-09-09T15:45:27.756000Z","shell.execute_reply.started":"2022-09-09T15:45:23.831571Z","shell.execute_reply":"2022-09-09T15:45:27.754717Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"MSE: 2979.4653710862585\nMAE: 31.015003680967233\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The test MAE is considerably better than all of the RNN models and is comparable to the Random Forest Regressor performance.. The MSE is pretty high but this is expected and actually only due to a single predicted price of the property:","metadata":{}},{"cell_type":"code","source":"plt.subplots(1, 2, figsize=(15, 4))\nplt.subplot(1, 2, 1)\nplt.title(\"Prediction\")\nplt.boxplot(prediction)\nplt.subplot(1, 2, 2)\nplt.title(\"Actual\")\nplt.boxplot(y_test_nlp)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T18:51:38.880747Z","iopub.execute_input":"2022-09-09T18:51:38.881330Z","iopub.status.idle":"2022-09-09T18:51:39.191308Z","shell.execute_reply.started":"2022-09-09T18:51:38.881287Z","shell.execute_reply":"2022-09-09T18:51:39.190327Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"{'whiskers': [<matplotlib.lines.Line2D at 0x7f7f5840e290>,\n  <matplotlib.lines.Line2D at 0x7f7f5840eb90>],\n 'caps': [<matplotlib.lines.Line2D at 0x7f7f5840e110>,\n  <matplotlib.lines.Line2D at 0x7f7f5840e3d0>],\n 'boxes': [<matplotlib.lines.Line2D at 0x7f7f5840e7d0>],\n 'medians': [<matplotlib.lines.Line2D at 0x7f83ea7fe390>],\n 'fliers': [<matplotlib.lines.Line2D at 0x7f83ea7fe490>],\n 'means': []}"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"def show_history(story):\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18.5, 10.5)\n    ax1.plot(story.history['mae'])\n    ax1.plot(story.history['val_mae'])\n    ax1.set(xlabel='epoch', ylabel='mae')\n    ax1.legend(['train_mae', 'test_mae'], loc='best')\n    ax1.set_title('MAE evolution during NN training')\n    \n    ax2.plot(story.history['loss'])\n    ax2.plot(story.history['val_loss'])\n    ax2.set(xlabel='epoch', ylabel='loss')\n    ax2.legend(['train_loss', 'test_loss'], loc='best')\n    ax2.set_title('Loss evolution during NN training')\n    plt.show()\n\nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T15:45:35.232457Z","iopub.execute_input":"2022-09-09T15:45:35.232836Z","iopub.status.idle":"2022-09-09T15:45:35.600398Z","shell.execute_reply.started":"2022-09-09T15:45:35.232781Z","shell.execute_reply":"2022-09-09T15:45:35.599274Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1332x756 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## 6. Comparison of word embeddings","metadata":{}},{"cell_type":"markdown","source":"As expected, using pre-trained embeddings will almost surely give better results than training embeddings from zero. \nIt is observed that the all the Deep Learning Models perform better with pre-trained word embedddings than the self-trained embeddings using TextVectorization(see Self_trained_emb_modeling_airbnb.ipynb) in our scenario. All models using pre-trained embeddings had better MAE and also did not overfit the training severly. On the other hand, the self-embedding models overfit the data even on using highly powerful neural networks, like LSTM,Cnn-LSTM and Bidirectional LSTM.  Also pre-trained word embeddings lead to a faster training and a lower final training loss. It can be interpreted that the model could pick up more semantic signals from the pre-trained embeddings than it did from the training data through the embedding layer. Therefore, we apply the pre-trained word embedding model to our Unseen(Test) Data.","metadata":{}},{"cell_type":"markdown","source":"## 7. Application to Test Set\n\nWe now train our full model on the entire training data again. Therefore we will use the embeddding matrices which we obtained after re-initializing our tokenizers so they take into account the whole set of words.","metadata":{}},{"cell_type":"code","source":"train_num = train.select_dtypes(exclude=[\"category\",\"datetime64[ns]\",\"object\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:51:53.551765Z","iopub.execute_input":"2022-09-09T17:51:53.552670Z","iopub.status.idle":"2022-09-09T17:51:53.562246Z","shell.execute_reply.started":"2022-09-09T17:51:53.552634Z","shell.execute_reply":"2022-09-09T17:51:53.561247Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"X = train_num.drop(['price'], axis=1) \ny = train_num[['price']]","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:01:20.170658Z","iopub.execute_input":"2022-09-09T17:01:20.171321Z","iopub.status.idle":"2022-09-09T17:01:20.183741Z","shell.execute_reply.started":"2022-09-09T17:01:20.171285Z","shell.execute_reply":"2022-09-09T17:01:20.182756Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def create_ann():\n    model = models.Sequential()\n    model.add(layers.Dense(16, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(8, activation='relu'))\n    # model.add(layers.Dense(1, activation='linear'))\n    # model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])\n    return model\n\n\nrnn_units = 128\n\ndef create_w2v_text_model(max_len,NUM_WORDS,wiki_weights):\n    model = models.Sequential()\n    model.add(layers.Input(shape=(max_len,), dtype=tf.int32))\n    model.add(layers.Embedding(input_dim=NUM_WORDS, output_dim=100, input_length=max_len,embeddings_initializer=Constant(wiki_weights),\n                     trainable=False) )\n    model.add(layers.Conv1D(filters=16,kernel_size=5))\n    model.add(layers.AveragePooling1D(pool_size=2,strides=2))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.LSTM(rnn_units, return_sequences=True, kernel_regularizer='l2'))\n    model.add(layers.Dense(1, activation=\"relu\"))\n    return model\n\n\ndef create_combined_model(X):\n    X = layers.Dropout(0.2)(X)\n    X = layers.Dense(128, activation=\"relu\")(X)\n    # X = layers.Dense(64, activation=\"relu\")(X)\n    X = layers.Dense(1, activation=\"relu\")(X)\n    print(X.shape)\n    return X\n\n\ndef create_model():\n    \n   ### Initialize Input layers\n    input_summary = tf.keras.Input(shape=(101,), dtype=tf.int32, name=\"summary\")\n    input_name = tf.keras.Input(shape=(8,), dtype=tf.int32, name=\"name\")\n    input_space = tf.keras.Input(shape=(116,), dtype=tf.int32, name=\"space\")\n    input_neighborhood_overview = tf.keras.Input(shape=(109,), dtype=tf.int32, name=\"neighborhood_overview\")\n    input_numeric = tf.keras.Input(shape=(train_num_cols.shape[1],), dtype=tf.float64, name=\"numeric\")\n    \n    ### Create Vectorisation models from text features\n    summary_model = create_w2v_text_model(101,NUM_WORDS_SUMMARY,wiki_weights_summary)\n    name_model = create_w2v_text_model(8,NUM_WORDS_NAME,wiki_weights_name)\n    space_model = create_w2v_text_model(116,NUM_WORDS_SPACE,wiki_weights_space)\n    neighborhood_overview_model = create_w2v_text_model(109,NUM_WORDS_NGBR,wiki_weights_ngbr)\n\n    ### Create Data flow\n    emb_summary = summary_model(input_summary)\n    emb_name = name_model(input_name)\n    emb_space = space_model(input_space)\n    emb_neighborhood_overview = neighborhood_overview_model(input_neighborhood_overview)\n    numeric_layers = create_ann()(input_numeric)\n\n    concat_combined = layers.Concatenate(axis=1)([\n                                                    emb_summary,\n                                                    emb_name,\n                                                    emb_space,\n                                                    emb_neighborhood_overview\n                                                    ])\n    print(concat_combined.shape)\n    concat_combined = layers.Flatten()(concat_combined)\n    concat_combined = layers.Concatenate()([concat_combined, numeric_layers])\n    output = create_combined_model(concat_combined)\n    \n    \n    ### Finalize the model\n    model = tf.keras.Model(inputs = [\n                                    input_summary, \n                                    input_name, \n                                    input_space, \n                                    input_neighborhood_overview,\n                                    input_numeric\n                                    ], \n                            outputs = output)\n    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4),\n                loss=losses.LogCosh(), metrics=['mae'])\n    return model\n\nmodel = create_model()\nprint(model.summary())\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, verbose=0, patience=3, restore_best_weights=True)\n\nhistory = model.fit(\n    {\n        \"summary\" : tf.convert_to_tensor(tr_summary), \n        \"name\" : tf.convert_to_tensor(tr_name),\n        \"space\" : tf.convert_to_tensor(tr_space),\n        \"neighborhood_overview\" : tf.convert_to_tensor(tr_ngbr),\n        \"numeric\" : tf.convert_to_tensor(X)\n    },\n    tf.convert_to_tensor(y.values),\n    validation_split=0.2,\n    epochs = 30,\n    batch_size = 64,\n    callbacks = [earlystopping],\n    verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:01:38.866320Z","iopub.execute_input":"2022-09-09T17:01:38.866927Z","iopub.status.idle":"2022-09-09T17:08:20.812957Z","shell.execute_reply.started":"2022-09-09T17:01:38.866882Z","shell.execute_reply":"2022-09-09T17:08:20.811963Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"(None, 158, 1)\n(None, 1)\nModel: \"model_16\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nsummary (InputLayer)            [(None, 101)]        0                                            \n__________________________________________________________________________________________________\nname (InputLayer)               [(None, 8)]          0                                            \n__________________________________________________________________________________________________\nspace (InputLayer)              [(None, 116)]        0                                            \n__________________________________________________________________________________________________\nneighborhood_overview (InputLay [(None, 109)]        0                                            \n__________________________________________________________________________________________________\nsequential_55 (Sequential)      (None, 48, 1)        1723385     summary[0][0]                    \n__________________________________________________________________________________________________\nsequential_56 (Sequential)      (None, 2, 1)         623385      name[0][0]                       \n__________________________________________________________________________________________________\nsequential_57 (Sequential)      (None, 56, 1)        1786785     space[0][0]                      \n__________________________________________________________________________________________________\nsequential_58 (Sequential)      (None, 52, 1)        1876185     neighborhood_overview[0][0]      \n__________________________________________________________________________________________________\nconcatenate_24 (Concatenate)    (None, 158, 1)       0           sequential_55[0][0]              \n                                                                 sequential_56[0][0]              \n                                                                 sequential_57[0][0]              \n                                                                 sequential_58[0][0]              \n__________________________________________________________________________________________________\nnumeric (InputLayer)            [(None, 33)]         0                                            \n__________________________________________________________________________________________________\nflatten_12 (Flatten)            (None, 158)          0           concatenate_24[0][0]             \n__________________________________________________________________________________________________\nsequential_59 (Sequential)      (None, 8)            680         numeric[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_25 (Concatenate)    (None, 166)          0           flatten_12[0][0]                 \n                                                                 sequential_59[0][0]              \n__________________________________________________________________________________________________\ndropout_63 (Dropout)            (None, 166)          0           concatenate_25[0][0]             \n__________________________________________________________________________________________________\ndense_115 (Dense)               (None, 128)          21376       dropout_63[0][0]                 \n__________________________________________________________________________________________________\ndense_116 (Dense)               (None, 1)            129         dense_115[0][0]                  \n==================================================================================================\nTotal params: 6,031,925\nTrainable params: 351,725\nNon-trainable params: 5,680,200\n__________________________________________________________________________________________________\nNone\nEpoch 1/30\n692/692 [==============================] - 20s 21ms/step - loss: 60.0092 - mae: 59.9635 - val_loss: 52.9473 - val_mae: 53.2177\nEpoch 2/30\n692/692 [==============================] - 13s 18ms/step - loss: 51.1651 - mae: 51.5551 - val_loss: 45.4235 - val_mae: 45.8856\nEpoch 3/30\n692/692 [==============================] - 14s 20ms/step - loss: 43.9419 - mae: 44.4353 - val_loss: 38.2281 - val_mae: 38.7440\nEpoch 4/30\n692/692 [==============================] - 13s 19ms/step - loss: 40.6229 - mae: 41.1487 - val_loss: 35.5759 - val_mae: 36.1084\nEpoch 5/30\n692/692 [==============================] - 13s 18ms/step - loss: 39.0855 - mae: 39.6238 - val_loss: 34.8088 - val_mae: 35.3520\nEpoch 6/30\n692/692 [==============================] - 13s 19ms/step - loss: 38.0839 - mae: 38.6330 - val_loss: 33.6345 - val_mae: 34.1886\nEpoch 7/30\n692/692 [==============================] - 13s 19ms/step - loss: 37.4158 - mae: 37.9746 - val_loss: 33.2421 - val_mae: 33.8042\nEpoch 8/30\n692/692 [==============================] - 13s 19ms/step - loss: 37.0374 - mae: 37.6050 - val_loss: 32.9826 - val_mae: 33.5518\nEpoch 9/30\n692/692 [==============================] - 13s 19ms/step - loss: 36.4394 - mae: 37.0140 - val_loss: 32.6834 - val_mae: 33.2602\nEpoch 10/30\n692/692 [==============================] - 13s 19ms/step - loss: 36.1163 - mae: 36.6971 - val_loss: 32.8343 - val_mae: 33.4180\nEpoch 11/30\n692/692 [==============================] - 13s 19ms/step - loss: 35.7829 - mae: 36.3689 - val_loss: 32.1844 - val_mae: 32.7730\nEpoch 12/30\n692/692 [==============================] - 13s 19ms/step - loss: 35.5075 - mae: 36.0978 - val_loss: 32.0322 - val_mae: 32.6244\nEpoch 13/30\n692/692 [==============================] - 13s 19ms/step - loss: 35.3328 - mae: 35.9282 - val_loss: 31.8651 - val_mae: 32.4602\nEpoch 14/30\n692/692 [==============================] - 13s 19ms/step - loss: 35.0386 - mae: 35.6370 - val_loss: 31.8542 - val_mae: 32.4518\nEpoch 15/30\n692/692 [==============================] - 13s 19ms/step - loss: 34.9011 - mae: 35.5024 - val_loss: 31.6427 - val_mae: 32.2438\nEpoch 16/30\n692/692 [==============================] - 13s 19ms/step - loss: 34.6986 - mae: 35.3030 - val_loss: 31.6207 - val_mae: 32.2266\nEpoch 17/30\n692/692 [==============================] - 13s 19ms/step - loss: 34.5674 - mae: 35.1747 - val_loss: 31.5354 - val_mae: 32.1434\nEpoch 18/30\n692/692 [==============================] - 13s 19ms/step - loss: 34.5177 - mae: 35.1273 - val_loss: 31.4712 - val_mae: 32.0803\nEpoch 19/30\n692/692 [==============================] - 13s 18ms/step - loss: 34.2789 - mae: 34.8904 - val_loss: 31.6793 - val_mae: 32.2895\nEpoch 20/30\n692/692 [==============================] - 14s 20ms/step - loss: 34.2099 - mae: 34.8230 - val_loss: 31.3653 - val_mae: 31.9788\nEpoch 21/30\n692/692 [==============================] - 13s 19ms/step - loss: 34.0107 - mae: 34.6253 - val_loss: 31.2457 - val_mae: 31.8596\nEpoch 22/30\n692/692 [==============================] - 13s 19ms/step - loss: 33.8871 - mae: 34.5024 - val_loss: 31.6054 - val_mae: 32.2223\nEpoch 23/30\n692/692 [==============================] - 14s 20ms/step - loss: 33.8850 - mae: 34.5010 - val_loss: 31.2800 - val_mae: 31.8972\nEpoch 24/30\n692/692 [==============================] - 13s 19ms/step - loss: 33.7022 - mae: 34.3189 - val_loss: 31.1158 - val_mae: 31.7336\nEpoch 25/30\n692/692 [==============================] - 13s 19ms/step - loss: 33.6513 - mae: 34.2693 - val_loss: 31.6427 - val_mae: 32.2611\nEpoch 26/30\n692/692 [==============================] - 13s 19ms/step - loss: 33.5438 - mae: 34.1617 - val_loss: 31.1358 - val_mae: 31.7531\nEpoch 27/30\n692/692 [==============================] - 13s 18ms/step - loss: 33.4146 - mae: 34.0330 - val_loss: 30.9904 - val_mae: 31.6091\nEpoch 28/30\n692/692 [==============================] - 13s 19ms/step - loss: 33.4111 - mae: 34.0299 - val_loss: 30.9819 - val_mae: 31.6000\nEpoch 29/30\n692/692 [==============================] - 13s 19ms/step - loss: 33.3599 - mae: 33.9797 - val_loss: 31.0715 - val_mae: 31.6897\nEpoch 30/30\n692/692 [==============================] - 14s 20ms/step - loss: 33.2309 - mae: 33.8502 - val_loss: 30.9809 - val_mae: 31.5982\n","output_type":"stream"}]},{"cell_type":"code","source":"final_composite_predictions = pd.DataFrame(model.predict([test_summary,test_name,test_space,test_ngbr, test_num_cols]), columns=[\"price\"], index=test.listing_id)\nfinal_composite_predictions","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:30:30.140935Z","iopub.execute_input":"2022-09-09T17:30:30.141295Z","iopub.status.idle":"2022-09-09T17:30:38.095247Z","shell.execute_reply.started":"2022-09-09T17:30:30.141265Z","shell.execute_reply":"2022-09-09T17:30:38.094190Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"                 price\nlisting_id            \n0FEMC4VA5U   89.851578\nPQ2BYEO0QR  115.335762\n3FP6WFHUBN   46.525352\nGG0V2KDG90   43.038242\nTZVVK4YSIO   91.290749\n...                ...\nSCRJ69GZPK  254.935471\nILZN192SUC   45.317337\nA44OQ7GPYY  174.624405\nKZ742YLH4X   71.349442\nYOCQ63ZYYD  100.309128\n\n[29769 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>listing_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0FEMC4VA5U</th>\n      <td>89.851578</td>\n    </tr>\n    <tr>\n      <th>PQ2BYEO0QR</th>\n      <td>115.335762</td>\n    </tr>\n    <tr>\n      <th>3FP6WFHUBN</th>\n      <td>46.525352</td>\n    </tr>\n    <tr>\n      <th>GG0V2KDG90</th>\n      <td>43.038242</td>\n    </tr>\n    <tr>\n      <th>TZVVK4YSIO</th>\n      <td>91.290749</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>SCRJ69GZPK</th>\n      <td>254.935471</td>\n    </tr>\n    <tr>\n      <th>ILZN192SUC</th>\n      <td>45.317337</td>\n    </tr>\n    <tr>\n      <th>A44OQ7GPYY</th>\n      <td>174.624405</td>\n    </tr>\n    <tr>\n      <th>KZ742YLH4X</th>\n      <td>71.349442</td>\n    </tr>\n    <tr>\n      <th>YOCQ63ZYYD</th>\n      <td>100.309128</td>\n    </tr>\n  </tbody>\n</table>\n<p>29769 rows  1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final_composite_predictions.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-09-09T17:31:03.185117Z","iopub.execute_input":"2022-09-09T17:31:03.185561Z","iopub.status.idle":"2022-09-09T17:31:03.243595Z","shell.execute_reply.started":"2022-09-09T17:31:03.185522Z","shell.execute_reply":"2022-09-09T17:31:03.242629Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"This project majorily focuses on Natural Language Processing and the data set was an apt representation of the industrial data. We were able to harness the predictive power of textual data, propotionally comparable to the non-text data. \nThe pre-trained word embeddings proved to outshone the pre-training of our own word embedddings, as is seen in the real world. The integration of text and non-text columns in the NLP pipeline gave the best results in the RNN architecture for both the labeled and unseen dataset. \n\nAlthough, potential improvements can be made to model by incorporating the image feature and review dataset. Addtionally,  data cleaning could be done even more thoroughly, since we are sure that there still exist anomalities in the text features. On the other hand, it would probably never be possible to fully clean this data set.\n\nFurthermore, a even more advanced and complex model architecture can be implemented which might prove to improve the overall model performance for instance transformer networks. However, we were able to strike a balance between model complexity and model performance through CNN-LSTMs. ","metadata":{}}]}